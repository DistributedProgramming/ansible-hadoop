<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>2. Japanese Document &mdash; Ansible playbooks to construct Hadoop environment</title>
    
    <link rel="stylesheet" href="_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Ansible playbooks to construct Hadoop environment" href="index.html" />
    <link rel="prev" title="1. English Document" href="english.html" /> 
  </head>
  <body>
      <div class="header"><h1 class="heading"><a href="index.html">
          <span>Ansible playbooks to construct Hadoop environment</span></a></h1>
        <h2 class="heading"><span>2. Japanese Document</span></h2>
      </div>
      <div class="topnav">
      
        <p>
        «&#160;&#160;<a href="english.html">1. English Document</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>
      <div class="content">
        
        
  <div class="section" id="japanese-document">
<h1>2. Japanese Document<a class="headerlink" href="#japanese-document" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>2.1. 概要<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>2.1.1. このプレイブック集について<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>このプレイブック集を利用すると、HA構成のHDFS、YARN環境を構築できます。
小さめのクラスタを立てるのに向いた内容となっているため、
大きなクラスタを立てる時にはHadoopやOSのパラメータチューニングが別途必要となることにご注意ください。</p>
<p>なお、このプレイブック集は、 <a class="reference external" href="https://bitbucket.org/dobachi/ansible-playbooks.git">dobachi&#8217;s ansible-playbooks</a> や
<a class="reference external" href="https://github.com/mcsrainbow/ansible-playbooks-cdh5">mcsrainbow&#8217;s ansible-playbooks-cdh5</a> などを参考に作りました。</p>
</div>
<div class="section" id="id3">
<h3>2.1.2. 特徴<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>このプレイブック集の機能は以下の通りです。
<em>各機能単体で利用できます。</em></p>
<ul class="simple">
<li>Ansible実行環境を整える</li>
<li>Hadoop環境用のAWS EC2インスタンスを起動する</li>
<li>HA構成のHDFS、YARN環境を構築する</li>
<li>CDH5のSpark Coreをインストールし、Sparkの実行環境を整える</li>
<li>コミュニティ版Spark Coreをインストールし、Sparkの実行環境を整える</li>
<li>Gangliaによるリソース可視化環境を整える</li>
<li>InfluxDBとGrafanaによるメトリクス可視化環境を整える</li>
<li>テスト用のPseudo環境を構築する</li>
<li>Sparkノートブック環境としてZeppelinの実行環境を整える</li>
</ul>
</div>
<div class="section" id="sec-servers-ja">
<span id="id4"></span><h3>2.1.3. サーバ構成<a class="headerlink" href="#sec-servers-ja" title="Permalink to this headline">¶</a></h3>
<p>このプレイブック集では以下のサーバ構成を前提としています。</p>
<p><strong>中規模クラスタ構成時のサーバ環境</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">サーバ名</th>
<th class="head">サービス構成</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>master01</td>
<td>Primary NameNode, JournalNode, Zookeeper Server(id=1), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master02</td>
<td>Backup NameNode, JournalNode, Zookeeper Server(id=2), Primary ResourceManager,
Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master03</td>
<td>JournalNode, Zookeeper Server(id=3), HistoryServer, Backup ResourceManager,
Ganglia Slave, Ganglia Master, InfluxDB, Grafana</td>
</tr>
<tr class="row-odd"><td>client01</td>
<td>Hadoop Client, Spark Core, Ganglia Slave, Zeppelin</td>
</tr>
<tr class="row-even"><td>slave01</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave02</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave03</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave04</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave05</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
</tbody>
</table>
<p><strong>大規模クラスタ構築時のサーバ構成</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Server</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>master01</td>
<td>Primary NameNode, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master02</td>
<td>Backup NameNode, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master03</td>
<td>Primary ResourceManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master04</td>
<td>Backup ResourceManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master05</td>
<td>JournalNode, Zookeeper Server(id=1), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master06</td>
<td>JournalNode, Zookeeper Server(id=2), Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master07</td>
<td>JournalNode, Zookeeper Server(id=3), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master08</td>
<td>HistoryServer, Ganglia Master, Ganglia Slave, InfluxDB, Grafana</td>
</tr>
<tr class="row-even"><td>client01</td>
<td>Hadoop Client, Spark Core, Ganglia Slave, Zeppelin</td>
</tr>
<tr class="row-odd"><td>slave01</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave02</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave03</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave04</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave05</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave06</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave07</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave08</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave09</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave10</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
</tbody>
</table>
<p><strong>疑似分散環境</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">サーバ名</th>
<th class="head">サービス構成</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>pseudo</td>
<td>NameNode, DataNode, SecondaryNameNode, ResourceManager, NodeManager,
Spark-core, Spark history server</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li>InfluxDB, Grafana, Zeppelinもプレイブックを利用して構成できます</li>
</ul>
</div>
<div class="section" id="id5">
<h3>2.1.4. ソフトウェア構成<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="71%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ソフトウェア</th>
<th class="head">バージョン等</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>OS</td>
<td>CentOS6.6 or CentOS7.0</td>
</tr>
<tr class="row-odd"><td>Hadoop</td>
<td>CDH5.3</td>
</tr>
<tr class="row-even"><td>Spark</td>
<td>Spark1.2 of CDH5
or Spark1.3 community edition</td>
</tr>
<tr class="row-odd"><td>Ansible</td>
<td>Ansible 1.8 of EPEL</td>
</tr>
<tr class="row-even"><td>InfluxDB</td>
<td>コミュニティ最新版</td>
</tr>
<tr class="row-odd"><td>Graphana</td>
<td>コミュニティ版1.9.1</td>
</tr>
<tr class="row-even"><td>Zeppelin</td>
<td>コミュニティ最新版</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id6">
<h3>2.1.5. 必要事項<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Ansibleを実行するサーバからすべてのサーバにSSHで到達性があることを前提としています</li>
<li>本ドキュメントの例では、実行ユーザがsudoできることを前提としています。
もしsudo権限が無いのであればrootユーザでSSH接続して実行する必要があります。</li>
<li>EC2上のサーバを構成管理する際には、RSA鍵を利用したSSHアクセスになります。
例えばCentOSコミュニティのCentOS6インスタンスの場合、標準ではrootユーザで
RSA鍵を利用してログインします。</li>
</ul>
</div>
</div>
<div class="section" id="getting-started">
<h2>2.2. Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>この節では、Hadoop HDFS/YARN環境を構築する流れを説明します。
各プレイブックの詳細は別節の説明をご覧ください。</p>
<div class="section" id="id7">
<h3>2.2.1. 簡単化のための前提<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference internal" href="#sec-servers-ja"><em>サーバ構成</em></a> に示された数のサーバを利用できること。またホスト名が正しく設定されていること。<ul>
<li>ホスト名は、master01, master02, master03, client01, slave01, slave02, slave03, slave04, slave05です。</li>
</ul>
</li>
<li>Ansibleを実行するサーバからクラスタの各サーバへホスト名でSSHログインできること<ul>
<li>例えば、/etc/hosts内にクラスタの各サーバについてのホスト名、IPアドレスが設定されていること。</li>
</ul>
</li>
<li>各サーバでsudoできること</li>
</ul>
</div>
<div class="section" id="install-ansible">
<h3>2.2.2. Install Ansible<a class="headerlink" href="#install-ansible" title="Permalink to this headline">¶</a></h3>
<p>EPELレポジトリをインストールします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y epel-release
</pre></div>
</div>
<p>Ansibleをインストールします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y ansible
</pre></div>
</div>
<div class="section" id="id8">
<h4>2.2.2.1. プレイブック集をクローンします<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>まず既存のファイルをmvします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd</span> /etc
<span class="nv">$ </span>sudo mv ansible ansible.org
</pre></div>
</div>
<p>クローンします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>git clone https://github.com/dobachi/ansible-hadoop.git ansible
</pre></div>
</div>
</div>
<div class="section" id="ansible">
<h4>2.2.2.2. Ansibleを基本設定します。<a class="headerlink" href="#ansible" title="Permalink to this headline">¶</a></h4>
<p>ansible.cfg.sampleをansible.cfgにコピーします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd </span>ansible
<span class="nv">$ </span>cp ansible.cfg.sample ansible.cfg
</pre></div>
</div>
<p>インベントリファイルのシンボリックリンクを作成します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ln -s hosts.sample hosts
</pre></div>
</div>
<p>各サーバの/etc/hostsにコピーされるテンプレートファイルを修正します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo vi roles/common/files/hosts.default
</pre></div>
</div>
</div>
<div class="section" id="hadoop">
<h4>2.2.2.3. Hadoopインストールと設定<a class="headerlink" href="#hadoop" title="Permalink to this headline">¶</a></h4>
<p>パッケージをインストールし、設定します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_all.yml -k -s -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
</pre></div>
</div>
<p>サービスを初期化します。
なお、HDFSを初期化する手順が含まれていますのでご注意ください。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_zkfc.yml -k -s
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_hdfs.yml -k -s
</pre></div>
</div>
<p>サービスを起動します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/start_cluster.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h4>2.2.2.4. おめでとうございます<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p>これでHDFSにアクセスできるようになりました。
client01から以下のコマンドを実行してください。</p>
<p>Example of the command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>hdfs dfs -ls /
</pre></div>
</div>
<p>HDFSのウェブサービスには以下のURLからアクセスできます。
片方ががアクティブで、片方がスタンバイです。</p>
<ul class="simple">
<li><a class="reference external" href="http://master01:50070">http://master01:50070</a></li>
<li><a class="reference external" href="http://master02:50070">http://master02:50070</a></li>
</ul>
<p>YARNのサンプルジョブを実行できます。</p>
<p>Example of the command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>hdfs dfs -mkdir /user/&lt;user name&gt;
<span class="nv">$ </span>hdfs dfs -chown &lt;user name&gt;:&lt;group name&gt; /user/&lt;user name&gt;
<span class="nv">$ </span>yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi <span class="m">100</span> 100
</pre></div>
</div>
<p>YARNのウェブサービスには以下のURLでアクセスできます。
片方ががアクティブで、片方がスタンバイです。</p>
<ul class="simple">
<li><a class="reference external" href="http://master02:8088">http://master02:8088</a></li>
<li><a class="reference external" href="http://master03:8088">http://master03:8088</a></li>
</ul>
</div>
<div class="section" id="spark">
<h4>2.2.2.5. Sparkコアのインストール<a class="headerlink" href="#spark" title="Permalink to this headline">¶</a></h4>
<p>コマンド例</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_spark.yml -k -s
</pre></div>
</div>
<p>これでclient01上で、spark-shellなどのコマンドを実行できるようになりました。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>spark-shell
</pre></div>
</div>
<p>上記コマンドの結果、YARNに接続した状態でSparkのシェルが起動します。
Sparkドライバのウェブサービスにアクセスするには、以下のURLを利用します。</p>
<ul class="simple">
<li><a class="reference external" href="http://client01:4040">http://client01:4040</a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="hosts">
<h2>2.3. hostsについて<a class="headerlink" href="#hosts" title="Permalink to this headline">¶</a></h2>
<p>本プレイブック集には2種類のhostsサンプルが付属しています。
主なコンポーネント構成は以下の通りです。</p>
<p>hosts.large_sample:</p>
<blockquote>
<div><ul class="simple">
<li>NameNode 2台</li>
<li>Zookeeper兼JournalNode 3台</li>
<li>ResourceManager 2台</li>
<li>Client 1台</li>
<li>Slave 10台</li>
</ul>
</div></blockquote>
<p>hosts.medium_sample:</p>
<blockquote>
<div><ul class="simple">
<li>Master 3台</li>
<li>Client 1台</li>
<li>Slave 5台</li>
</ul>
</div></blockquote>
<p>hosts.medium_sampleについては、マスタ系サービスが一部同居構成になっています。</p>
<p>また両サンプルともに、疑似分散環境用のhadoop_pseudoグループが定義されています。</p>
</div>
<div class="section" id="id10">
<h2>2.4. インベントリのグループ定義について<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p>インベントリのサンプルファイには、以下のようなグループ定義が含まれています。</p>
<p><strong>主なグループ</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="24%" />
<col width="76%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">グループ名</th>
<th class="head">説明</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>production</td>
<td>トップグループです。環境固有のグループパラメータを設定するために
用いられます。</td>
</tr>
<tr class="row-odd"><td>local</td>
<td>localhostを定義するためのダミーグループです</td>
</tr>
<tr class="row-even"><td>hadoop_all</td>
<td>Hadoopクラスタ全体を表すグループです</td>
</tr>
<tr class="row-odd"><td>hadoop_master</td>
<td>マスタサービスを提供するグループやノードを含むグループです</td>
</tr>
<tr class="row-even"><td>hadoop_namenode</td>
<td>プライマリNameNodeとバックアップNameNodeの両方を含むグループです</td>
</tr>
<tr class="row-odd"><td>hadoop_journalnode</td>
<td>JournalNodeを含むグループです</td>
</tr>
<tr class="row-even"><td>hadoop_zookeeperserver</td>
<td>Zookeeperノードを含むグループです。
&#8220;zookeeper_server_id&#8221;というパラメータがノードごとに設定されます。</td>
</tr>
<tr class="row-odd"><td>hadoop_resourcemanager</td>
<td>ResourceManagersを含むグループです</td>
</tr>
<tr class="row-even"><td>hadoop_other</td>
<td>Hadoopの関連サービスを提供するノードを含むグループです。
たとえばヒストリサーバなどが該当します。</td>
</tr>
<tr class="row-odd"><td>hadoop_slave</td>
<td>スレーブノードを含むグループです</td>
</tr>
<tr class="row-even"><td>hadoop_client</td>
<td>様々なサービスのクライアント機能を提供するノードを含むグループです</td>
</tr>
<tr class="row-odd"><td>hadoop_pseudo</td>
<td>疑似分散環境を提供するグループです</td>
</tr>
</tbody>
</table>
<p>もし複数の環境を管理していて異なるパラメータを与えたい場合、
トップレベルのグループをそれらの環境固有パラメータを設定する場所として利用するとよいです。
そのようなシチュエーションとしては、例えばテスト環境と本番環境を両方同じ
Ansibleプレイブックで運用しているときが挙げられます。</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre>group_vars/all/something        ... 各環境共通のデフォルト値が定義されます
group_vars/production/something ... 本番環境固有のパラメータ設定が定義されます
group_vars/test/something       ... テスト環境固有のパラメータ設定が定義されます
</pre></div>
</div>
<p>またトップレベルの異なる複数のインベントリファイルを定義しておき、
ansible-playbookコマンドを実行するときに明示的に指定することで、
実行時に環境を切り替えて使うことができます。</p>
</div>
<div class="section" id="id11">
<h2>2.5. プレイブック集について<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>このプロジェクトには2種類のプレイブックが含まれています。</p>
<ul class="simple">
<li>構成管理のためのプレイブック集<ul>
<li>パッケージをインストールしたり、パラメータを設定するために利用されます。</li>
<li>（例）Hadoopコアパッケージのインストール</li>
</ul>
</li>
<li>運用作業のためのプレイブック<ul>
<li>OSサービスやミドルウェアの運用作業を行うためのプレイブック集です。</li>
<li>（例）HDFSのフォーマット</li>
</ul>
</li>
</ul>
<div class="section" id="id12">
<h3>2.5.1. 構成管理のためのプレイブック集<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>playbooks/confディレクトリ以下に以下のプレイブック集があります。</p>
<table border="1" class="docutils">
<colgroup>
<col width="41%" />
<col width="59%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ディレクトリ</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>playbooks/conf/common</td>
<td>コモンな設定。OSの設定。</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/cdh5</td>
<td>CDH5のHDFS/YARN環境の構築／設定</td>
</tr>
<tr class="row-even"><td>playbooks/conf/cdh5_pseudo</td>
<td>CDH5の疑似分散環境の構築/設定</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/ansible</td>
<td>Ansibleの実行環境の設定</td>
</tr>
<tr class="row-even"><td>playbooks/conf/ganglia</td>
<td>Ganglia環境の構築／設定</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/influxdb</td>
<td>InfluxDBとGrafanaの構築／設定</td>
</tr>
<tr class="row-even"><td>playbooks/conf/spark_comm</td>
<td>コミュニティ版Sparkの構築/設定</td>
</tr>
</tbody>
</table>
<div class="section" id="common">
<h4>2.5.1.1. common<a class="headerlink" href="#common" title="Permalink to this headline">¶</a></h4>
<p>基本的な設定を行います。</p>
<ul class="simple">
<li>playbooks/conf/common/common_all.yml<ul>
<li>すべての基本的な設定を行うプレイブックです</li>
</ul>
</li>
<li>playbooks/conf/common/common_only_common.yml<ul>
<li>「common」ロールのみ実行するプレイブックです</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="cdh5">
<h4>2.5.1.2. cdh5<a class="headerlink" href="#cdh5" title="Permalink to this headline">¶</a></h4>
<p>CDH5のHDFS/YARN環境の構築／設定を行います。</p>
<ul class="simple">
<li>cdh5_all.yml<ul>
<li>他のプレイブックのラッパーです</li>
<li>すべてのサーバの構成管理を実行できます</li>
</ul>
</li>
<li>cdh5_cl.yml<ul>
<li>Hadoopクライアント環境を構成管理します</li>
<li>「cdh5_cl」ロールを実行します</li>
</ul>
</li>
<li>cdh5_journalnode.yml<ul>
<li>HDFS JournalNodeを構成管理します</li>
<li>「cdh5_jn」ロールを実行します</li>
</ul>
</li>
<li>cdh5_namenode.yml<ul>
<li>HDFS NameNodeを構成管理します</li>
<li>「cdh5_nn」ロールを実行します</li>
</ul>
</li>
<li>cdh5_other.yml<ul>
<li>MapReduce HistoryServerとYARN Proxy環境を構成管理します</li>
<li>「cdh5_ot」ロールを実行します</li>
</ul>
</li>
<li>cdh5_resourcemanager.yml<ul>
<li>YARN ResouceManagerを構成管理します</li>
<li>「cdh5_rm」ロールを実行します</li>
</ul>
</li>
<li>cdh5_slave.yml<ul>
<li>HDFS DataNodeとYARN NodeManagerを構成管理します</li>
<li>「cdh5_sl」ロールを実行します</li>
</ul>
</li>
<li>cdh5_spark.yml<ul>
<li>Hadoopクライアント環境のSparkコアを構成管理します</li>
<li>「cdh5_spark」ロールを実行します</li>
</ul>
</li>
<li>cdh5_zookeeper.yml<ul>
<li>Zookeeperを構成管理します</li>
<li>「zookeeper_server」ロールを実行します</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="cdh5-pseudo">
<h4>2.5.1.3. cdh5_pseudo<a class="headerlink" href="#cdh5-pseudo" title="Permalink to this headline">¶</a></h4>
<p>CDH5のHDFS/YARNのPseudo環境を構築／設定します。</p>
<ul class="simple">
<li>cdh5_pseudo.yml<ul>
<li>Pseudo環境を構築、設定します</li>
</ul>
</li>
<li>cdh5_spark.yml<ul>
<li>Spark環境をPseudo環境に構築、設定します</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id13">
<h4>2.5.1.4. ansible<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h4>
<p>Ansible実行環境を構成管理します。</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Hadoop HDFS/YARN環境を構成管理するにあたっては、
このプレイブック集は必須ではありません。
もし手動でAnsible実行環境を構成管理した場合は不要です。</p>
</div>
<ul class="simple">
<li>ansible_client.yml<ul>
<li>Ansibleを実行する構成管理サーバ（このプロジェクトではHadoopクライアント環境としています）上に
Ansible実行環境を構築します</li>
<li>「ansible」ロールを実行します</li>
</ul>
</li>
<li>ansible_remote.yml<ul>
<li>Ansibleを高速化するためのパッケージをリモートサーバ群にインストールします</li>
<li>「ansible_remote」ロールを実行します</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="ganglia">
<h4>2.5.1.5. ganglia<a class="headerlink" href="#ganglia" title="Permalink to this headline">¶</a></h4>
<p>Gangliaを構成管理します。
Gangliaはマスタ／スレーブ構成なのでそれぞれを管理するためのプレイブックがあります。</p>
<ul class="simple">
<li>ganglia_all.yml<ul>
<li>マスタとスレーブを構成するプレイブックのラッパーです</li>
</ul>
</li>
<li>ganglia_master.yml<ul>
<li>マスタを構成するためのプレイブックです</li>
</ul>
</li>
<li>ganglia_slave.yml<ul>
<li>スレーブを構成するためのプレイブックです</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="influxdb">
<h4>2.5.1.6. influxdb<a class="headerlink" href="#influxdb" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>all.yml<ul>
<li>InfluxDBとGrafanaを設定します</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="spark-comm">
<h4>2.5.1.7. spark_comm<a class="headerlink" href="#spark-comm" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>all.yml<ul>
<li>クラスタ全体の設定</li>
</ul>
</li>
<li>spark_base.yml<ul>
<li>全ノード共通の基本設定</li>
</ul>
</li>
<li>spark_client.yml<ul>
<li>アプリケーションを開発すためのクライアント環境の整備</li>
</ul>
</li>
<li>spark_history.yml<ul>
<li>Sparkのヒストリサーバを起動するための設定</li>
</ul>
</li>
<li>spark_libs.yml<ul>
<li>MLlibでネイティブライブラリを利用するための設定</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id14">
<h3>2.5.2. 運用作業のためのプレイブック集<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>playbooks/operationディレクトリ以下に運用作業のためのプレイブック集があります。</p>
<table border="1" class="docutils">
<colgroup>
<col width="33%" />
<col width="67%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ディレクトリ</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>playbooks/operation/cdh5</td>
<td>Hadoop HDFS/YARNサービスの運用に用います
例えばHDFSの初期化や各サービスの起動／停止です。</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/cdh5_pseudo</td>
<td>Hadoop HDFS/YARNサービスの運用に用います
例えばHDFSの初期化や各サービスの起動／停止です。</td>
</tr>
<tr class="row-even"><td>playbooks/operation/ec2</td>
<td>Hadoop用のAWS EC2インスタンスを起動します</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/httpd</td>
<td>HTTPサービスを起動／停止します</td>
</tr>
<tr class="row-even"><td>playbooks/operation/influxdb</td>
<td>InfluxDBを初期化します</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/spark_com</td>
<td>コミュニティ版Sparkのビルドやサービスの起動/停止に用います</td>
</tr>
</tbody>
</table>
<div class="section" id="id15">
<h4>2.5.2.1. cdh5<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<p>Hadoopの各サービスを運用するためのプレイブック集です。
詳しくはディレクトリ内のREADMEを参照ください。</p>
</div>
<div class="section" id="ec2">
<h4>2.5.2.2. ec2<a class="headerlink" href="#ec2" title="Permalink to this headline">¶</a></h4>
<p>AWS EC2インスタンスを起動するためのプレイブック集です。
詳しくはディレクトリ内のREADMEを参照ください。</p>
</div>
<div class="section" id="id16">
<h4>2.5.2.3. influxdb<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>create_db.yml<ul>
<li>すべての必要なデータベースをInfluxDBに作成します。</li>
</ul>
</li>
<li>create_graphite_db.yml<ul>
<li>InfluxDBにGraphiteプロトコルで受領したデータを格納するデータベースを作成します。
主にSparkのGraphiteプロトコルによるメトリクスを保存するために使用します。</li>
</ul>
</li>
<li>create_grafana_db.yml<ul>
<li>Grafanaのダッシュボード情報を保存するデータベースをInfluxDBに作成します。</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id17">
<h4>2.5.2.4. spark_comm<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>make_spark_packages.yml<ul>
<li>Sparkソースコードのコンパイルとパッケージ作成</li>
</ul>
</li>
<li>start_spark_historyserver.yml<ul>
<li>Sparkのヒストリサーバを起動する</li>
</ul>
</li>
<li>stop_spark_historyserver.yml<ul>
<li>Sparkのヒストリサーバを停止する</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="id18">
<h2>2.6. ロールについて<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h2>
<p>この節では、プレイブックの中で呼び出されるロールについて説明します。</p>
<div class="section" id="id19">
<h3>2.6.1. 基本的な設定のためのロール<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>common</td>
<td>OSや基本的なサービスの設定</td>
</tr>
<tr class="row-odd"><td>jdk</td>
<td>JDKの設定</td>
</tr>
<tr class="row-even"><td>scala</td>
<td>Hadoopクライアント環境のScala実行環境の整備</td>
</tr>
<tr class="row-odd"><td>screen</td>
<td>screenの設定</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id20">
<h3>2.6.2. Ansible実行環境を構成管理のためのロール<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ansible</td>
<td>Ansible実行環境の構成管理</td>
</tr>
<tr class="row-odd"><td>ansible_remote</td>
<td>Ansible高速化のためのリモート側の構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="aws-ec2">
<h3>2.6.3. AWS EC2管理のためのロール<a class="headerlink" href="#aws-ec2" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ec2_hadoop</td>
<td>Hadoop用のAWS EC2起動</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="cdh5hadoop">
<h3>2.6.4. CDH5のHadoop環境のロール<a class="headerlink" href="#cdh5hadoop" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_base</td>
<td>Hadoopの基本的な構成管理（設定ファル配備など）</td>
</tr>
<tr class="row-odd"><td>cdh5_jn</td>
<td>JournalNodeの構成管理</td>
</tr>
<tr class="row-even"><td>cdh5_nn</td>
<td>NameNodeの構成管理</td>
</tr>
<tr class="row-odd"><td>cdh5_ot</td>
<td>HistoryServerとYARN Proxyの構成管理</td>
</tr>
<tr class="row-even"><td>cdh5_rm</td>
<td>ResourceManagerの構成管理</td>
</tr>
<tr class="row-odd"><td>cdh5_sl</td>
<td>DataNodeとNodeManagerの構成管理</td>
</tr>
<tr class="row-even"><td>zookeeper_server</td>
<td>Zookeeper serverの構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="cdh5hadoop-pseudo">
<h3>2.6.5. CDH5のHadoop Pseudo環境のロール<a class="headerlink" href="#cdh5hadoop-pseudo" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_pseudo</td>
<td>Hadoop Pseudo環境の構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id21">
<h3>2.6.6. Spark実行環境の構成管理<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_spark</td>
<td>Hadoopクライアント環境のSparkコアの構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id22">
<h3>2.6.7. Ganglia艦橋の構成管理<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ganglia_master</td>
<td>Gangliaのマスタとウェブフロントエンドの構成管理</td>
</tr>
<tr class="row-odd"><td>ganglia_slave</td>
<td>Gangliaのスレーブの構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="influxdbgrafana">
<h3>2.6.8. InfluxDBとGrafanaの構成管理<a class="headerlink" href="#influxdbgrafana" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>influxdb</td>
<td>InfluxDBの構成管理</td>
</tr>
<tr class="row-odd"><td>grafana</td>
<td>Grafanaの構成管理</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id23">
<h3>2.6.9. コミュニティ版Sparkの構成管理<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">ロール名</th>
<th class="head">用途</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>spark_comm</td>
<td>コミュニティ版Sparkの構成管理</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id24">
<h2>2.7. プレイブックの利用方法<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<p>この節では、プレイブックを使って各サービスを構成管理する例を示します。
なお、各プレイブックはそれぞれ個別に実行できます。</p>
<div class="section" id="id25">
<h3>2.7.1. 前提条件<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>You have servers described insection.</li>
<li>サーバの構成は <a class="reference internal" href="#sec-servers-ja"><em>サーバ構成</em></a> 節の内容に従っているものとします。</li>
</ul>
</div>
<div class="section" id="sec-configure-ansible-env-ja">
<span id="id26"></span><h3>2.7.2. Ansible実行環境を構成管理する例<a class="headerlink" href="#sec-configure-ansible-env-ja" title="Permalink to this headline">¶</a></h3>
<p>この節では、Ansibleをインストールするところから初めて、
プレイブックを使ってAnsible実行環境を構成管理する例を示します。</p>
<div class="section" id="id27">
<h4>2.7.2.1. パッケージのインストール<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h4>
<p>EPELレポジトリをインストールします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y epel-release
</pre></div>
</div>
<p>Ansibleをインストールします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y ansible
</pre></div>
</div>
</div>
<div class="section" id="id28">
<h4>2.7.2.2. 本プレイブック集のクローン<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h4>
<p>まずオリジナルの/etc/ansibleディレクトリをmvします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd</span> /etc
<span class="nv">$ </span>sudo mv ansible ansible.org
</pre></div>
</div>
<p>gitレポジトリからプレイブック集をクローンします。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>git clone https://github.com/dobachi/ansible-hadoop.git ansible
</pre></div>
</div>
</div>
<div class="section" id="id29">
<h4>2.7.2.3. Ansibleの設定修正<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h4>
<p>/etc/hosts にコピーされるhostsのテンプレートを修正します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd </span>ansible
<span class="nv">$ </span>sudo vi roles/common/files/hosts.default
</pre></div>
</div>
</div>
<div class="section" id="id30">
<h4>2.7.2.4. プレイブック実行<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h4>
<p>最初はインベントリのサンプルファイルhosts.sampleを使ってローカルホストに基本的な設定を行います。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/common/common_all.yml -k -s -i hosts.sample -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
</pre></div>
</div>
<p>なおオプションで渡しているcommon_hosts_replaceという変数は、
/etc/hostsファイルを置き換えるかどうかを設定するものです。
今回は置き換えるためにTrueとしています。</p>
<p>つぎに/etc/ansible/hosts.defaultにコピーされるインベントリファイルのテンプレートを修正します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo vi roles/ansible/templates/hosts.default.j2
</pre></div>
</div>
<p>ansible_client.ymlを実行し、Ansible実行環境を整備します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e <span class="s2">&quot;ansible_environment=default ansible_modify_cfg=True&quot;</span>
</pre></div>
</div>
<p>なおオプションで渡しているansible_environmentという変数は、
インベントリファイルのサフィックスを表します。
またansible_modify_cfgという変数は、
ansible.cfgを置き換えるかどうかを設定するものです。
今回は置き換えるためにTrueとしています。</p>
<p>もしHadoopクラスタがEC2インスタンスで構成されている場合、
SSHログインの際に鍵認証が必要になります。
ansible.cfg内で鍵のPATHを指定するために、「ansible_private_key_file」という変数を設定します。
この場合の実行コマンド例を以下に示します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e <span class="s2">&quot;ansible_environment=default ansible_modify_cfg=True ansible_private_key_file=</span><span class="si">${</span><span class="nv">HOME</span><span class="si">}</span><span class="s2">/mykey.pem&quot;</span>
</pre></div>
</div>
<p>最後に、全サーバにSSHログイン可能かどうか確認します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible -m ping hadoop_all -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="id31">
<h3>2.7.3. EC2インスタンスの構成<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h3>
<p>この節では、Hadoop用のAWS EC2インスタンスを起動するための手順例を示します。</p>
<div class="section" id="id32">
<h4>2.7.3.1. 前提<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>本プレイブック集を利用して、もしくは手動で、Ansible実行環境が設定されていること</li>
</ul>
</div>
<div class="section" id="id33">
<h4>2.7.3.2. 環境変数の設定<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h4>
<p>AWS access keyなどを設定します。
アクセス鍵についてはAWSのページを参照し、あらかじめ作成してください。</p>
<p>以下のような環境変数を定義します。</p>
<div class="highlight-python"><div class="highlight"><pre>export AWS_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXx
export AWS_SECRET_KEY=XXXXXXXXXXXXXXXXXXXXXXXXX
</pre></div>
</div>
</div>
<div class="section" id="ec2-hadoop">
<h4>2.7.3.3. 「ec2_hadoop」ロールのパラメータ設定<a class="headerlink" href="#ec2-hadoop" title="Permalink to this headline">¶</a></h4>
<p>パラメータはroles/ec2_hadoop/defaults/main.ymlに定義されています。
ただし設定必要なパラメータは、最初コメントアウトされた状態になっています。
各自の値を設定し、コメントアウトを解除してください。</p>
<p>なお、group_vas/all/ec2等のグループ変数に記載しても良いです。
設定例を以下に示します。</p>
<div class="highlight-python"><div class="highlight"><pre>ec2_hadoop_group_id: sg-xxxxxxxx

ec2_hadoop_accesskey: xxxxx

ec2_hadoop_itype: xx.xxxxx

ec2_hadoop_master_image: ami-xxxxxxxx
ec2_hadoop_slave_image: ami-xxxxxxxx
ec2_hadoop_client_image: ami-xxxxxxxx

ec2_hadoop_region: xx-xxxxxxxxx-x

ec2_hadoop_vpc_subnet_id: subnet-xxxxxxxx
</pre></div>
</div>
<p>もし設定漏れがある場合は以下のようなメッセージが出力されますので、
すべてのパラメータを設定するようにしてください。:</p>
<div class="highlight-python"><div class="highlight"><pre>One or more undefined variables: &#39;ec2_hadoop_group_id&#39; is undefined
</pre></div>
</div>
</div>
<div class="section" id="id34">
<h4>2.7.3.4. プレイブックの実行<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h4>
<p>ansible-playbookコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -k
</pre></div>
</div>
<p>成功した場合は <em>/tmp/ec2_&lt;プレイブックを実行したときのUNIXエポック時刻&gt;</em> のディレクトリ以下に以下の内容のファイルが配備されています。
EC2インスタンスにアクセスしたり、EC2インスタンスによるクラスタを構成管理する際に利用してください。</p>
<ul class="simple">
<li>プレイベートIPアドレス、パブリックIPアドレスの一覧</li>
<li>クラスタ内で利用できるAnsibleインベントリファイルのサンプル</li>
<li>クラスタ内で利用できる/etc/hostsファイルのサンプル</li>
</ul>
</div>
<div class="section" id="id35">
<h4>2.7.3.5. （補足）EC2インスタンスを再起動した場合<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h4>
<p>EC2インスタンスを再起動するとpublicなIPアドレスが変わります。
その場合はもう一度プレイブックを実行すると、改めてIPアドレス一覧のファイルが生成されます。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -k
</pre></div>
</div>
</div>
</div>
<div class="section" id="id36">
<h3>2.7.4. ホスト名の設定<a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h3>
<p>「common」ロールを使って各サーバのホスト名を設定できます。
主にEC2インスタンスでHadoopクラスタを構成した際に、
自動付与されたホスト名から扱いやすいホスト名に変更する場合に利用します。</p>
<div class="section" id="id37">
<h4>2.7.4.1. 前提<a class="headerlink" href="#id37" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>本プレイブック集を利用して、もしくは手動で、Ansible実行環境が設定されていること</li>
</ul>
</div>
<div class="section" id="id38">
<h4>2.7.4.2. 手順<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd</span> /etc/ansible
<span class="nv">$ </span>ansible-playbook playbooks/conf/common/common_only_common.yml -k -s -e <span class="s2">&quot;common_config_hostname=True server=hadoop_all&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="cdh5hdfs-yarn">
<h3>2.7.5. CDH5のHDFS/YARN環境を構成する例<a class="headerlink" href="#cdh5hdfs-yarn" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id39">
<h4>2.7.5.1. 前提条件<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>本プレイブック集を利用して、もしくは手動で、Ansible実行環境が設定されていること</li>
</ul>
</div>
<div class="section" id="id40">
<h4>2.7.5.2. 手順<a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。</p>
<p>なお、ここではオプションでcommon_hosts_replace変数をTrueにしているため、
各サーバの/etc/hostsを置き換えることに注意してください。
/etc/ansible/roles/common/files/hosts.defaultの内容に置き換えられます。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_all.yml -k -s -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_zkfc.yml -k -s
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_hdfs.yml -k -s
</pre></div>
</div>
<p>適切に設定されたらサービスを起動してください:</p>
<div class="highlight-python"><div class="highlight"><pre>$ ansible-playbook playbooks/operation/cdh5/start_cluster.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="id41">
<h4>2.7.5.3. Spark実行環境の整備<a class="headerlink" href="#id41" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_spark.yml -k -s
</pre></div>
</div>
<p>Sparkのヒストリサーバを起動する場合は以下のコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/start_sparkhistory.yml -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="cdh5pseudo">
<h3>2.7.6. CDH5のPseudo環境を構成する例<a class="headerlink" href="#cdh5pseudo" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id42">
<h4>2.7.6.1. 前提条件<a class="headerlink" href="#id42" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>本プレイブック集を利用して、もしくは手動で、Ansible実行環境が設定されていること</li>
</ul>
</div>
<div class="section" id="id43">
<h4>2.7.6.2. 手順<a class="headerlink" href="#id43" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。
各サーバの/etc/hostsを置き換えることに注意してください。
/etc/ansible/roles/common/files/hosts.defaultの内容に置き換えられます。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_pseudo.yml -k -s -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5_pseudo/init_hdfs.yml -k -s
</pre></div>
</div>
<p>適切に設定されたらサービスを起動してください:</p>
<div class="highlight-python"><div class="highlight"><pre>$ ansible-playbook playbooks/operation/cdh5_pseudo/start_cluster.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="cdh5pseudospark">
<h4>2.7.6.3. CDH5のPseudo環境にSpark実行環境を整備<a class="headerlink" href="#cdh5pseudospark" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_spark.yml -k -s
</pre></div>
</div>
<p>Sparkのヒストリサーバを起動する場合は以下のコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5_pseudo/start_sparkhistory.yml -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="id44">
<h3>2.7.7. Ganglia環境を構成する<a class="headerlink" href="#id44" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id45">
<h4>2.7.7.1. 前提条件<a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>本プレイブック集を利用して、もしくは手動で、Ansible実行環境が設定されていること</li>
</ul>
</div>
<div class="section" id="id46">
<h4>2.7.7.2. 手順<a class="headerlink" href="#id46" title="Permalink to this headline">¶</a></h4>
<p>以下の通り、ansible-playbookコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/ganglia/ganglia_all.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="gmond">
<h4>2.7.7.3. gmondでユニキャストを使う方法<a class="headerlink" href="#gmond" title="Permalink to this headline">¶</a></h4>
<p>デフォルトでは、マルチキャストを使うようになっています。
EC2インスタンスでクラスタを構成している場合など、
マルチキャストを利用できない時はユニキャストを利用することになります。</p>
<p>そのためには、&#8221;ganglia_slave_use_unicast&#8221;というパラメータをTrueに設定してください。</p>
<p>例（group_vars/all/ganglia）:</p>
<div class="highlight-python"><div class="highlight"><pre>ganglia_slave_use_unicast: True
</pre></div>
</div>
<p>また合わせて&#8221;ganglia_slave_host&#8221;というパラメータも設定するようにしてください。
このパラメータは、gmondがメトリクスを送る対象を示します。
多くの場合、Gangliaのマスタデーモンgmetadは、
各グループの代表サーバをポーリングします。
このポーリングする対象を&#8221;ganglia_slave_host&#8221;の設定値にするとよいです。</p>
</div>
</div>
<div class="section" id="id47">
<h3>2.7.8. InfluxDBとGrafanaを構成する<a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h3>
<p>InfluxDBとGrafanaをインストールするには以下のコマンドを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/influxdb/all.yml -k -s
</pre></div>
</div>
<p>Graphiteプロトコルで受領したデータを格納するデータベースを
InfluxDB内の作成します。
これは主にSparkのメトリクスを受領するために用います。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/influxdb/create_graphite_db.yml -k -s
</pre></div>
</div>
<p>Grafanaのダッシュボード情報を格納するデータベースを作成します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/influxdb/create_grafana_db.yml -k -s
</pre></div>
</div>
<p>なお、作成するデータベースの名前や接続に使用するユーザ名は、
group_vars/all/influxdbにて以下のように設定しています。</p>
<p><strong>group_vars/all/meta</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">meta_graphitedb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;graphite&#39;</span>
<span class="l-Scalar-Plain">meta_grafanadb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;grafana&#39;</span>
</pre></div>
</div>
<p><strong>group_vars/all/influxdb</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">influxdb_server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_admin_user</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
<span class="l-Scalar-Plain">influxdb_graphite_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_grafana_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
</pre></div>
</div>
<p><strong>group_vars/all/grafana</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">grafana_influxdb_list</span><span class="p-Indicator">:</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;false&quot;</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;true&quot;</span>
</pre></div>
</div>
<p>またGrafanaのグラフを設定する方法は、  <a class="reference external" href="http://grafana.org/docs/features/intro/">Grafana&#8217;s documents</a>
などをご参照ください。</p>
</div>
<div class="section" id="id48">
<h3>2.7.9. コミュニティ版Sparkを構成する<a class="headerlink" href="#id48" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id49">
<h4>2.7.9.1. パッケージの取得、もしくはビルド<a class="headerlink" href="#id49" title="Permalink to this headline">¶</a></h4>
<p><a class="reference external" href="https://spark.apache.org/downloads.html">Spark公式ダウンロードサイト</a> から
ビルド済みパッケージを取得できます。</p>
<p>もし何らかの理由で自分でビルドしたい場合は、
<a class="reference external" href="https://spark.apache.org/docs/latest/building-spark.html">Spark公式のビルド手順</a> を参照ください。</p>
<p>またplaybooks/operation/spark_comm/make_spark_packages.ymlというプレイブックを利用することも可能です。
その場合、以下に示すパラメータを任意で設定してください。</p>
<ul class="simple">
<li>spark_comm_src_dir</li>
<li>spark_comm_version</li>
<li>spark_comm_mvn_options</li>
<li>spark_comm_hadoop_version</li>
</ul>
</div>
<div class="section" id="id52">
<h4>2.7.9.2. パラメータの設定<a class="headerlink" href="#id52" title="Permalink to this headline">¶</a></h4>
<p>コミュニティ版Sparkの構成には、playbooks/conf/spark_comm/all.ymlというプレイブックを利用できます。</p>
<p>このプレイブックはHTTPでビルド済みパッケージを取得することを前提としています。
そのためのダウンロードURLを設定するため、以下のパラメータを任意に定義してください。</p>
<ul class="simple">
<li>spark_comm_package_url_base</li>
<li>spark_comm_package_name</li>
</ul>
<p>なお、ダウンロードURLは {{ spark_comm_package_url_base }}/{{ spark_comm_package_name }}.tgz のようになります。
例えばダウンロードURLが&#8221;<a class="reference external" href="http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz">http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz</a>&#8220;のとき、
spark_comm_package_url_baseは&#8221;<a class="reference external" href="http://example.local/spark">http://example.local/spark</a>&#8220;となり、spark_comm_package_nameは&#8221;spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2&#8221;となります。</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">spark_comm_package_nameが&#8221;.tgz&#8221;を含まないことに注意してください</p>
</div>
</div>
<div class="section" id="id53">
<h4>2.7.9.3. プレイブックの実行<a class="headerlink" href="#id53" title="Permalink to this headline">¶</a></h4>
<p>パラメータの設定後は、プレイブックを実行します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/spark_comm/all.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="id54">
<h4>2.7.9.4. ヒストリサーバの起動<a class="headerlink" href="#id54" title="Permalink to this headline">¶</a></h4>
<p>ヒストリサーバを起動します。</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/spark_comm/start_spark_historyserver.yml -k -s
</pre></div>
</div>
</div>
</div>
</div>
</div>


      </div>
      <div class="bottomnav">
      
        <p>
        «&#160;&#160;<a href="english.html">1. English Document</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>

    <div class="footer">
        &copy; Copyright 2014, dobachi.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>