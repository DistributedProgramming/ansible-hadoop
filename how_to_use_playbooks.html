<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>How to use this playbooks &mdash; Ansible playbooks to construct Hadoop environment</title>
    
    <link rel="stylesheet" href="_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Ansible playbooks to construct Hadoop environment" href="index.html" /> 
  </head>
  <body role="document">
      <div class="header" role="banner"><h1 class="heading"><a href="index.html">
          <span>Ansible playbooks to construct Hadoop environment</span></a></h1>
        <h2 class="heading"><span>How to use this playbooks</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>
      <div class="content">
        
        
  <div class="section" id="how-to-use-this-playbooks">
<h1>How to use this playbooks<a class="headerlink" href="#how-to-use-this-playbooks" title="Permalink to this headline">¶</a></h1>
<p>You can use these playbooks to configure the following configuration.
<strong>These playbooks are independent of each other</strong> .</p>
<ul class="simple">
<li>Ansible client environment to use various Ansible functions</li>
<li>Host name configuration</li>
<li>CDH5 HDFS/YARN environment</li>
</ul>
<div class="section" id="assumption-of-this-section">
<h2>Assumption of this section<a class="headerlink" href="#assumption-of-this-section" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>You have servers described in <a class="reference internal" href="english.html#sec-servers"><span>Servers</span></a> section.</li>
</ul>
</div>
<div class="section" id="how-to-configure-ansible-execution-environment">
<span id="sec-configure-ansible-env"></span><h2>How to configure Ansible execution environment<a class="headerlink" href="#how-to-configure-ansible-execution-environment" title="Permalink to this headline">¶</a></h2>
<p>If you have not configured Ansible execution environment,
you can use the following playbooks for it.</p>
<p>In this section, we start from installing Ansible packages.</p>
<div class="section" id="install-packages">
<h3>Install packages<a class="headerlink" href="#install-packages" title="Permalink to this headline">¶</a></h3>
<p>Install EPEL repository</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y epel-release
</pre></div>
</div>
<p>Install Ansible</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo yum install -y ansible
</pre></div>
</div>
</div>
<div class="section" id="clone-playbooks">
<h3>Clone playbooks<a class="headerlink" href="#clone-playbooks" title="Permalink to this headline">¶</a></h3>
<p>Move original /etc/ansible</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd</span> /etc
<span class="nv">$ </span>sudo mv ansible ansible.org
</pre></div>
</div>
<p>Clone this repository</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>git clone https://github.com/dobachi/ansible-hadoop.git ansible
</pre></div>
</div>
</div>
<div class="section" id="modify-configuration">
<h3>Modify configuration<a class="headerlink" href="#modify-configuration" title="Permalink to this headline">¶</a></h3>
<p>Modify hosts file to be copied to /etc/hosts</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd </span>ansible
<span class="nv">$ </span>sudo vi roles/common/files/hosts.default
</pre></div>
</div>
</div>
<div class="section" id="execute-playbooks-one-by-one">
<h3>Execute playbooks one by one<a class="headerlink" href="#execute-playbooks-one-by-one" title="Permalink to this headline">¶</a></h3>
<p>Execute ansible-playbook command with common_all.yml</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/common/common_all.yml -k -s -i hosts.sample -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
</pre></div>
</div>
<p>Copy ansible&#8217;s hosts and modify it</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>sudo vi roles/ansible/templates/hosts.default.j2
</pre></div>
</div>
<p>Execute ansible-playbook command with ansible_client.yml</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e <span class="s2">&quot;ansible_environment=default ansible_modify_cfg=True&quot;</span>
</pre></div>
</div>
<p>If you use EC2 and need a private key for SSH,
you should specify &#8220;ansible_private_key_file&#8221; paramter.
You should execute command with the parameter instead of the above command</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e <span class="s2">&quot;ansible_environment=default ansible_modify_cfg=True ansible_private_key_file=</span><span class="si">${</span><span class="nv">HOME</span><span class="si">}</span><span class="s2">/mykey.pem&quot;</span>
</pre></div>
</div>
<p>Check whether all nodes are reachable and &#8220;sudo&#8221; is available</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible -m ping hadoop_all -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="how-to-boot-ec2-instances-for-hadoop-cluster">
<h2>How to boot EC2 instances for Hadoop cluster<a class="headerlink" href="#how-to-boot-ec2-instances-for-hadoop-cluster" title="Permalink to this headline">¶</a></h2>
<p>If you want to use Hadoop on EC2 instances,
you can use playbooks/operation/ec2/hadoop_nodes_up.yml to boot instances.</p>
<div class="section" id="create-inventory-file">
<h3>Create inventory file<a class="headerlink" href="#create-inventory-file" title="Permalink to this headline">¶</a></h3>
<p>If you don&#8217;t have an inventory file,
create inventory file, /etc/ansible/hosts while referring /etc/ansible/hosts.sample.</p>
</div>
<div class="section" id="define-environment-variables-for-aws-access">
<h3>Define environment variables for AWS access<a class="headerlink" href="#define-environment-variables-for-aws-access" title="Permalink to this headline">¶</a></h3>
<p>We use environment variables to configure AWS access keys.
Define AWS_ACCESS_KEY and AWS_SECRET_KEY in your ~/.bashrc</p>
<div class="highlight-python"><div class="highlight"><pre>export AWS_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXx
export AWS_SECRET_KEY=XXXXXXXXXXXXXXXXXXXXXXXXX
</pre></div>
</div>
<p>If you don&#8217;t have AWS keys,
create keys while referring AWS web site.</p>
</div>
<div class="section" id="define-parameters-for-ec2-hadoop-role">
<h3>Define parameters for ec2_hadoop role<a class="headerlink" href="#define-parameters-for-ec2-hadoop-role" title="Permalink to this headline">¶</a></h3>
<p>You can find the parameter description for ec2_hadoop role in roles/ec2_hadoop/defaults/main.yml</p>
<p>To define your own parameters,
you need to create the group variable file (e.g. group_vars/all/ec2) and write parameter defines in this file.</p>
<p>The following is an example of group_vas/top.</p>
<div class="highlight-python"><div class="highlight"><pre>ec2_hadoop_group_id: sg-xxxxxxxx

ec2_hadoop_accesskey: xxxxx

ec2_hadoop_itype: xx.xxxxx

ec2_hadoop_master_image: ami-xxxxxxxx
ec2_hadoop_slave_image: ami-xxxxxxxx
ec2_hadoop_client_image: ami-xxxxxxxx

ec2_hadoop_region: xx-xxxxxxxxx-x

ec2_hadoop_vpc_subnet_id: subnet-xxxxxxxx
</pre></div>
</div>
<p>If you don&#8217;t define required parameters,
you will see some errors, like:</p>
<div class="highlight-python"><div class="highlight"><pre>One or more undefined variables: &#39;ec2_hadoop_group_id&#39; is undefined
</pre></div>
</div>
</div>
<div class="section" id="apply-playbook">
<h3>Apply playbook<a class="headerlink" href="#apply-playbook" title="Permalink to this headline">¶</a></h3>
<p>Execute ansible-playbook command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -c <span class="nb">local</span>
</pre></div>
</div>
<p>As a result, you can find an IP address list, an ansible inventory file and an example of /etc/hosts used in EC2 instances
in /tmp/ec2_&lt;unix epoc time&gt;.
&lt;unix epoc time&gt; is the time you executed this playbook.</p>
</div>
<div class="section" id="supplement-when-you-restart-ec2-instances">
<h3>(supplement) When you restart ec2 instances<a class="headerlink" href="#supplement-when-you-restart-ec2-instances" title="Permalink to this headline">¶</a></h3>
<p>When you restart ec2 instances, public IP addresses may change.
You can obtain new IP address tables by executing the playbook.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -c <span class="nb">local</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="how-to-configure-host-names-of-nodes">
<h2>How to configure host names of nodes<a class="headerlink" href="#how-to-configure-host-names-of-nodes" title="Permalink to this headline">¶</a></h2>
<p>If you want to configure hostname of nodes,
You can use &#8220;common&#8221; role and related playbooks.</p>
<p>Execute ansible-playbook command with common_only_common.yml</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span><span class="nb">cd</span> /etc/ansible
<span class="nv">$ </span>ansible-playbook playbooks/conf/common/common_only_common.yml -k -s -e <span class="s2">&quot;common_config_hostname=True server=hadoop_all&quot;</span>
</pre></div>
</div>
<p>This is usefull for configuration of EC2 instance, because your node may have variety of hostname after each node booted.</p>
</div>
<div class="section" id="how-to-configure-cdh5-hdfs-yarn-environment">
<h2>How to configure CDH5 HDFS/YARN environment<a class="headerlink" href="#how-to-configure-cdh5-hdfs-yarn-environment" title="Permalink to this headline">¶</a></h2>
<p>You can construct CDH5 HDFS/YARN environment by ansible-playbook command.</p>
<div class="section" id="preparement">
<h3>Preparement<a class="headerlink" href="#preparement" title="Permalink to this headline">¶</a></h3>
<p>If you have not configured Ansible execution environment,
you should configure it.
You can reference <a class="reference internal" href="#sec-configure-ansible-env"><span>How to configure Ansible execution environment</span></a> section.</p>
</div>
<div class="section" id="procedure">
<h3>Procedure<a class="headerlink" href="#procedure" title="Permalink to this headline">¶</a></h3>
<p>In the following example, we configure common_hosts_replace is True.
As a result of this parameter configuration, Ansible replace /etc/hosts
by Ansible driver server&#8217;s /etc/ansible/roles/common/files/hosts.default</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_all.yml -k -s -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_zkfc.yml -k -s
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/init_hdfs.yml -k -s
</pre></div>
</div>
<p>Start services</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/start_cluster.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="how-to-install-spark-environment-on-cdh5-environment">
<h3>How to install Spark environment on CDH5 environment<a class="headerlink" href="#how-to-install-spark-environment-on-cdh5-environment" title="Permalink to this headline">¶</a></h3>
<p>You can install Spark Core into Client node by the following command</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5/cdh5_spark.yml -k -s
</pre></div>
</div>
<p>If you want to start Spark&#8217;s history server,
please execute the following command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5/start_sparkhistory.yml -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="how-to-configure-cdh5-pseudo-environment">
<h2>How to configure CDH5 Pseudo environment<a class="headerlink" href="#how-to-configure-cdh5-pseudo-environment" title="Permalink to this headline">¶</a></h2>
<p>You can construct CDH5 HDFS/YARN environment by ansible-playbook command.</p>
<div class="section" id="id1">
<h3>Preparement<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>If you have not configured Ansible execution environment,
you should configure it.
You can reference <a class="reference internal" href="#sec-configure-ansible-env"><span>How to configure Ansible execution environment</span></a> section.</p>
</div>
<div class="section" id="id2">
<h3>Procedure<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>In the following example, we configure common_hosts_replace is True.
As a result of this parameter configuration, Ansible replace /etc/hosts
by Ansible driver server&#8217;s /etc/ansible/roles/common/files/hosts.default</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_pseudo.yml -k -s -e <span class="s2">&quot;common_hosts_replace=True&quot;</span>
<span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5_pseudo/init_hdfs.yml -k -s
</pre></div>
</div>
<p>Start services</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5_pseudo/start_cluster.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="how-to-install-spark-environment-on-hadoop-pseudo-environment">
<h3>How to install Spark environment on Hadoop pseudo environment<a class="headerlink" href="#how-to-install-spark-environment-on-hadoop-pseudo-environment" title="Permalink to this headline">¶</a></h3>
<p>You can install Spark Core into Client node by the following command</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_spark.yml -k -s
</pre></div>
</div>
<p>If you want to start Spark&#8217;s history server,
please execute the following command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/cdh5_pseudo/start_sparkhistory.yml -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="how-to-install-ganglia-environment">
<h2>How to install Ganglia environment<a class="headerlink" href="#how-to-install-ganglia-environment" title="Permalink to this headline">¶</a></h2>
<p>You can install Gaglia services with the following command:</p>
<div class="highlight-python"><div class="highlight"><pre>.. code-block:: shell
</pre></div>
</div>
<blockquote>
<div>$ ansible-playbook playbooks/conf/ganglia/ganglia_all.yml -k -s</div></blockquote>
<div class="section" id="how-to-use-unicast-for-communication-between-gmonds">
<h3>How to use unicast for communication between gmonds<a class="headerlink" href="#how-to-use-unicast-for-communication-between-gmonds" title="Permalink to this headline">¶</a></h3>
<p>This playbook uses multicast for communication between gmonds as default.
In some situcation, you may want to use unicast.
For example, you are using ec2 of AWS.</p>
<p>The parameter &#8220;ganglia_slave_use_unicast&#8221; is used to define
whether you use unicast or not.
If you set this parameter True in your group_vars, you can use unicast.</p>
<p>Example(group_vars/all/ganglia):</p>
<div class="highlight-python"><div class="highlight"><pre>ganglia_slave_use_unicast: True
</pre></div>
</div>
<p>Please configure the parameter &#8220;ganglia_slave_host&#8221; as well as &#8220;ganglia_slave_use_unicast&#8221;
This parameter is used to define the destination which each gmond sends metrics,
and should be a representative node which gmetad connect.</p>
</div>
</div>
<div class="section" id="how-to-install-and-configure-influxdb-and-grafana">
<h2>How to install and configure InfluxDB and Grafana<a class="headerlink" href="#how-to-install-and-configure-influxdb-and-grafana" title="Permalink to this headline">¶</a></h2>
<p>You can install InfluxDB and Grafana services with the followign command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/influxdb/all.yml -k -s
</pre></div>
</div>
<p>Then, create a database in InfulxDB to hold data gathered by Graphite&#8217;s protocol.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/influxdb/create_graphite_db.yml -k -s
</pre></div>
</div>
<p>Create a database in InfulxDB to store Grafana&#8217;s dashboard data.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/influxdb/create_grafana_db.yml -k -s
</pre></div>
</div>
<p>The database&#8217;s name and user name to connect the database is
configured in group_vars/all/meta, group_vars/all/influxdb and group_vars/all/grafana like the following.</p>
<p><strong>group_vars/all/meta</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">meta_graphitedb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;graphite&#39;</span>
<span class="l-Scalar-Plain">meta_grafanadb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;grafana&#39;</span>
</pre></div>
</div>
<p><strong>group_vars/all/influxdb</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">influxdb_server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_admin_user</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
<span class="l-Scalar-Plain">influxdb_graphite_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_grafana_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
</pre></div>
</div>
<p><strong>group_vars/all/grafana</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">grafana_influxdb_list</span><span class="p-Indicator">:</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;false&quot;</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;true&quot;</span>
</pre></div>
</div>
<p>Please read <a class="reference external" href="http://grafana.org/docs/features/intro/">Grafana&#8217;s documents</a> to learn
how to configure graphs.</p>
</div>
<div class="section" id="how-to-install-spark-community-edition">
<h2>How to install Spark community edition<a class="headerlink" href="#how-to-install-spark-community-edition" title="Permalink to this headline">¶</a></h2>
<div class="section" id="obtain-package-or-compile-sources">
<h3>Obtain package or compile sources<a class="headerlink" href="#obtain-package-or-compile-sources" title="Permalink to this headline">¶</a></h3>
<p>You can get Spark pacakge from <a class="reference external" href="https://spark.apache.org/downloads.html">Spark official download site</a> .</p>
<p>If you want to use a package compiled by your self,
you should build it according to <a class="reference external" href="https://spark.apache.org/docs/latest/building-spark.html">Spark offical build procedure</a> .</p>
<p>You can also use playbooks/operation/spark_comm/make_spark_packages.yml to build it.
When you use this playbook, please specify the following parameters used in this playbook.</p>
<ul class="simple">
<li>spark_comm_src_dir</li>
<li>spark_comm_version</li>
<li>spark_comm_mvn_options</li>
<li>spark_comm_hadoop_version</li>
</ul>
</div>
<div class="section" id="confiure-parameters">
<h3>Confiure parameters<a class="headerlink" href="#confiure-parameters" title="Permalink to this headline">¶</a></h3>
<p>You can use playbooks/conf/spark_comm/all.yml to configure Spark community edition envirionment.</p>
<p>This playbooks and roles expect to get Spark tar package by HTTP method.
You should configure the following parameter to specify where Ansible should get Spark tar package.</p>
<ul class="simple">
<li>spark_comm_package_url_base</li>
<li>spark_comm_package_name</li>
</ul>
<p>The download URL is consited like {{ spark_comm_package_url_base }}/{{ spark_comm_package_name }}.tgz
For example, if the download URL is &#8220;<a class="reference external" href="http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz">http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz</a>&#8221;,
spark_comm_package_url_base is &#8220;<a class="reference external" href="http://example.local/spark">http://example.local/spark</a>&#8221; and spark_comm_package_name is &#8220;spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2&#8221;.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">spark_comm_package_name does not include &#8221;.tgz&#8221;</p>
</div>
</div>
<div class="section" id="execute-playbooks">
<h3>Execute playbooks<a class="headerlink" href="#execute-playbooks" title="Permalink to this headline">¶</a></h3>
<p>After configuration of parameters, you can execute Ansible playbooks.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/spark_comm/all.yml -k -s
</pre></div>
</div>
</div>
<div class="section" id="stat-history-server">
<h3>Stat history server<a class="headerlink" href="#stat-history-server" title="Permalink to this headline">¶</a></h3>
<p>Start Spark&#8217;s history server by the following command.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/spark_comm/start_spark_historyserver.yml -k -s
</pre></div>
</div>
</div>
</div>
<div class="section" id="configure-zeppelin">
<h2>Configure Zeppelin<a class="headerlink" href="#configure-zeppelin" title="Permalink to this headline">¶</a></h2>
<div class="section" id="obtain-sources-and-build">
<h3>Obtain sources and build<a class="headerlink" href="#obtain-sources-and-build" title="Permalink to this headline">¶</a></h3>
<p>First, according to <a class="reference external" href="https://github.com/apache/incubator-zeppelin/blob/master/README.md">Official README</a> , you need to compile source codes and make a package.</p>
<p>Please take care about the compile option.
You should specify Spark and Hadoop versions you use now.</p>
<p>The following is an example to configure CDH5.3.3、Spark1.3、YARN environment.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>mvn clean package -Pspark-1.3 -Dhadoop.version<span class="o">=</span>2.5.0-cdh5.3.3 -Phadoop-2.4 -Pyarn -DskipTests
</pre></div>
</div>
<p>You can also use playbooks/operation/zeppelin/build.yml, the helper playbook.
Before executing this playbook, please configure the following parameters in the playbook.</p>
<ul class="simple">
<li>zeppelin_git_url</li>
<li>zeppelin_src_dir</li>
<li>zeppelin_version</li>
<li>zeppelin_comiple_flag</li>
<li>zeppelin_hadoop_version</li>
</ul>
<p>Finally, the playbook to configure Zeppelin make use of the package
which you compiled the above procedure.
The package is downloaded from web service by HTTP,
so that you need to put the package on a HTTP web server.</p>
</div>
<div class="section" id="executing-playbook">
<h3>Executing playbook<a class="headerlink" href="#executing-playbook" title="Permalink to this headline">¶</a></h3>
<p>To configure Zeppelin, please execute the following playbook.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/conf/zeppelin/zeppelin.yml -k -s
</pre></div>
</div>
<p>After finishing configuration, you need to start Zeppelin service.</p>
<div class="highlight-shell"><div class="highlight"><pre><span class="nv">$ </span>ansible-playbook playbooks/operation/zeppelin/start_zeppelin.yml -k -s
</pre></div>
</div>
</div>
</div>
</div>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &copy; Copyright 2014, dobachi.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.
    </div>
  </body>
</html>