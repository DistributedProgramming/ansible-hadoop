

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>English Document &mdash; Ansible playbooks to construct Hadoop environment</title>
    
    <link rel="stylesheet" href="_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/print.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/theme_extras.js"></script>
    <link rel="top" title="Ansible playbooks to construct Hadoop environment" href="index.html" /> 
  </head>
  <body>
      <div class="header"><h1 class="heading"><a href="index.html">
          <span>Ansible playbooks to construct Hadoop environment</span></a></h1>
        <h2 class="heading"><span>English Document</span></h2>
      </div>
      <div class="topnav">
      
        <p>
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>
      <div class="content">
        
        
  <div class="section" id="english-document">
<h1>English Document<a class="headerlink" href="#english-document" title="Permalink to this headline">¶</a></h1>
<div class="section" id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Permalink to this headline">¶</a></h2>
<div class="section" id="about-playbooks">
<h3>About playbooks<a class="headerlink" href="#about-playbooks" title="Permalink to this headline">¶</a></h3>
<p>This is a library of playbooks to construct HDFS/YARN clusters.
You will have HDFS and YARN services with HA.</p>
<p>Although the configuration of OS and middlewares are not well tuned about performance,
this is enough to be used to construct small cluster.
In other words, if you would like to construct and manage large clusters,
you may need to configure OS and middlewares adequately.</p>
<p>To write these playbooks, <a class="reference external" href="https://bitbucket.org/dobachi/ansible-playbooks.git">dobachi&#8217;s ansible-playbooks</a>
and <a class="reference external" href="https://github.com/mcsrainbow/ansible-playbooks-cdh5">mcsrainbow&#8217;s ansible-playbooks-cdh5</a> are used as reference.</p>
</div>
<div class="section" id="feature">
<h3>Feature<a class="headerlink" href="#feature" title="Permalink to this headline">¶</a></h3>
<p>This project has the following functions.
Each function is available individually.</p>
<ul class="simple">
<li>Configuring Ansible execution environment</li>
<li>Booting EC2 instances for Hadoop cluster</li>
<li>Configuring HDFS/YARN with NameNode HA</li>
<li>Configuring CDH5&#8217;s Spark core on Client node</li>
<li>Configuring Spark community edition&#8217;s core on Client node</li>
<li>Configuring Ganglia for the resource visualization</li>
<li>Configuring InfluxDB and Grafana for the metrics visualization</li>
<li>Configuring Pseudo environment for test</li>
<li>Configuring Zeppelin for Spark notebook</li>
<li>Configuring fluentd and td-agent</li>
<li>Configuring Kafka cluster</li>
<li>Configuring Confluent cluster</li>
<li>Configuring Ambari</li>
</ul>
</div>
<div class="section" id="servers">
<span id="sec-servers"></span><h3>Servers<a class="headerlink" href="#servers" title="Permalink to this headline">¶</a></h3>
<p>This project&#8217;s assumption about middleware components and servers.</p>
<p><strong>Servers for medium cluster</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Server</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>master01</td>
<td>Primary NameNode, JournalNode, Zookeeper Server(id=1), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master02</td>
<td>Backup NameNode, JournalNode, Zookeeper Server(id=2), Primary ResourceManager,
Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master03</td>
<td>JournalNode, Zookeeper Server(id=3), HistoryServer, Backup ResourceManager,
Ganglia Slave, Ganglia Master, InfluxDB, Grafana</td>
</tr>
<tr class="row-odd"><td>client01</td>
<td>Hadoop Client, Spark Core, Ganglia Slave, Zeppelin</td>
</tr>
<tr class="row-even"><td>slave01</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave02</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave03</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave04</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave05</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>kafka01</td>
<td>Kafka broker</td>
</tr>
<tr class="row-even"><td>kafka02</td>
<td>Kafka broker</td>
</tr>
<tr class="row-odd"><td>kafka03</td>
<td>Kafka broker</td>
</tr>
<tr class="row-even"><td>manage</td>
<td>Ambari server</td>
</tr>
</tbody>
</table>
<p><strong>Servers for large cluster</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Server</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>master01</td>
<td>Primary NameNode, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master02</td>
<td>Backup NameNode, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master03</td>
<td>Primary ResourceManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master04</td>
<td>Backup ResourceManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master05</td>
<td>JournalNode, Zookeeper Server(id=1), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master06</td>
<td>JournalNode, Zookeeper Server(id=2), Ganglia Slave</td>
</tr>
<tr class="row-even"><td>master07</td>
<td>JournalNode, Zookeeper Server(id=3), Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>master08</td>
<td>HistoryServer, Ganglia Master, Ganglia Slave, InfluxDB, Grafana</td>
</tr>
<tr class="row-even"><td>client01</td>
<td>Hadoop Client, Spark Core, Ganglia Slave, Zeppelin</td>
</tr>
<tr class="row-odd"><td>slave01</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave02</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave03</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave04</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave05</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave06</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave07</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave08</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>slave09</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-even"><td>slave10</td>
<td>DataNode, NodeManager, Ganglia Slave</td>
</tr>
<tr class="row-odd"><td>kafka01</td>
<td>Kafka broker</td>
</tr>
<tr class="row-even"><td>kafka02</td>
<td>Kafka broker</td>
</tr>
<tr class="row-odd"><td>kafka03</td>
<td>Kafka broker</td>
</tr>
<tr class="row-even"><td>manage</td>
<td>Ambari server</td>
</tr>
</tbody>
</table>
<p><strong>Server for pseudo environment</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="91%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Server</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>pseudo</td>
<td>NameNode, DataNode, SecondaryNameNode, ResourceManager, NodeManager,
Spark-core, Spark history server</td>
</tr>
</tbody>
</table>
<ul class="simple">
<li>You can also configure InfluxDB, Grafana, Zeppelin by using playbooks</li>
</ul>
</div>
<div class="section" id="software-information">
<h3>Software information<a class="headerlink" href="#software-information" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="14%" />
<col width="86%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Software</th>
<th class="head">Version</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>OS</td>
<td>CentOS6.6 or CentOS7.0</td>
</tr>
<tr class="row-odd"><td>Hadoop</td>
<td>CDH5.3</td>
</tr>
<tr class="row-even"><td>Spark</td>
<td>Spark1.2 of CDH5
or Spark community edition</td>
</tr>
<tr class="row-odd"><td>Ansible</td>
<td>Ansible 1.8.2 of EPEL</td>
</tr>
<tr class="row-even"><td>InfluxDB</td>
<td>Latest version of the community</td>
</tr>
<tr class="row-odd"><td>Graphana</td>
<td>1.9.1 of the community</td>
</tr>
<tr class="row-even"><td>Zeppelin</td>
<td>Latest version of the community</td>
</tr>
<tr class="row-odd"><td>Kafka</td>
<td>0.10.0.0</td>
</tr>
<tr class="row-even"><td>Confluent</td>
<td>3.0.0</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="prerequirement">
<h3>Prerequirement<a class="headerlink" href="#prerequirement" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>You can login to each server by SSH from the server where you execute ansible.</li>
<li>You can use &#8220;sudo&#8221; in each server.
If you cannot use sudo, you should access remote servers by root user.</li>
<li>When you manage EC2 instances, you need to use RSA key to login servers.
For example, CentOS6 community instance use RSA key with root user in SSH access.</li>
</ul>
</div>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>In this section, the procedure to constuct HDFS/YARN environment is explained.</p>
<div class="section" id="prerequirement-for-simplicity">
<h3>Prerequirement for simplicity<a class="headerlink" href="#prerequirement-for-simplicity" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>You have enough number of servers. The host names of servers are shown in <a class="reference internal" href="#sec-servers"><em>Servers</em></a><ul>
<li>eg. master01, master02, master03, client01, slave01, slave02, slave03, slave04, slave05</li>
</ul>
</li>
<li>You can login to each server by SSH from the server where you execute ansible by the host names.<ul>
<li>eg. Your server has configured /etc/hosts to access Hadoop cluster&#8217;s servers.</li>
</ul>
</li>
<li>You can use &#8220;sudo&#8221; in each server</li>
</ul>
</div>
<div class="section" id="install-ansible">
<h3>Install Ansible<a class="headerlink" href="#install-ansible" title="Permalink to this headline">¶</a></h3>
<p>Install EPEL repository</p>
<div class="highlight-shell"><pre>$ sudo yum install -y epel-release</pre>
</div>
<p>Install Ansible</p>
<div class="highlight-shell"><pre>$ sudo yum install -y ansible</pre>
</div>
<div class="section" id="clone-playbooks">
<h4>Clone playbooks<a class="headerlink" href="#clone-playbooks" title="Permalink to this headline">¶</a></h4>
<p>Move original /etc/ansible</p>
<div class="highlight-shell"><pre>$ cd /etc
$ sudo mv ansible ansible.org</pre>
</div>
<p>Clone this repository</p>
<div class="highlight-shell"><pre>$ git clone https://github.com/dobachi/ansible-hadoop.git ansible</pre>
</div>
</div>
<div class="section" id="modify-configuration-of-ansible">
<h4>Modify configuration of Ansible<a class="headerlink" href="#modify-configuration-of-ansible" title="Permalink to this headline">¶</a></h4>
<p>Copy ansible.cfg.sample to ansible.cfg</p>
<div class="highlight-shell"><pre>$ cd ansible
$ cp ansible.cfg.sample ansible.cfg</pre>
</div>
<p>Create symbolic link of inventory file.</p>
<div class="highlight-shell"><pre>$ ln -s hosts.sample hosts</pre>
</div>
<p>Modify hosts file to be copied to /etc/hosts</p>
<div class="highlight-shell"><pre>$ sudo vi roles/common/files/hosts.default</pre>
</div>
</div>
<div class="section" id="install-and-configure-hadoop">
<h4>Install and configure Hadoop<a class="headerlink" href="#install-and-configure-hadoop" title="Permalink to this headline">¶</a></h4>
<p>Install and configure Hadoop.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5/cdh5_all.yml -k -s -e "common_hosts_replace=True"</pre>
</div>
<p>Initilize Hadoop environment.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5/init_zkfc.yml -k -s
$ ansible-playbook playbooks/operation/cdh5/init_hdfs.yml -k -s</pre>
</div>
<p>Start services</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5/start_cluster.yml -k -s</pre>
</div>
</div>
<div class="section" id="congratulation">
<h4>Congratulation!<a class="headerlink" href="#congratulation" title="Permalink to this headline">¶</a></h4>
<p>Now, you can access HDFS from client01.</p>
<p>Example of the command.</p>
<div class="highlight-shell"><pre>$ hdfs dfs -ls /</pre>
</div>
<p>You can access the web service of HDFS with the following URL.
(One of them is Active and another is Standby)</p>
<ul class="simple">
<li><a class="reference external" href="http://master01:50070">http://master01:50070</a></li>
<li><a class="reference external" href="http://master02:50070">http://master02:50070</a></li>
</ul>
<p>And, you can execute sample jobs from client01.</p>
<p>Example of the command.</p>
<div class="highlight-shell"><pre>$ hdfs dfs -mkdir /user/&lt;user name&gt;
$ hdfs dfs -chown &lt;user name&gt;:&lt;group name&gt; /user/&lt;user name&gt;
$ yarn jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar pi 100 100</pre>
</div>
<p>You can access the web service of YARN with the following URL.
(One of them is Active and another is Standby)</p>
<ul class="simple">
<li><a class="reference external" href="http://master02:8088">http://master02:8088</a></li>
<li><a class="reference external" href="http://master03:8088">http://master03:8088</a></li>
</ul>
</div>
<div class="section" id="install-spark-core">
<h4>Install Spark core<a class="headerlink" href="#install-spark-core" title="Permalink to this headline">¶</a></h4>
<p>Example of commands.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5/cdh5_spark.yml -k -s</pre>
</div>
<p>Now, you can use Spark&#8217;s commands, such as spark-shell.</p>
<div class="highlight-shell"><pre>$ spark-shell</pre>
</div>
<p>As a result, you can run spark-shell with YARN environment.</p>
<p>You can access the web service of Spark driver with the following URL.</p>
<ul class="simple">
<li><a class="reference external" href="http://client01:4040">http://client01:4040</a></li>
</ul>
</div>
</div>
</div>
<div class="section" id="about-hosts-inventory-file">
<h2>About hosts(inventory file)<a class="headerlink" href="#about-hosts-inventory-file" title="Permalink to this headline">¶</a></h2>
<p>We have two types of Ansible hosts sample.
The following is the location of the main services.</p>
<p>hosts.medium_sample:</p>
<blockquote>
<div><ul class="simple">
<li>Master Services(NameNode, Zookeeper, JournalNode and ResourceManager): 3 nodes</li>
<li>Client: 1 node</li>
<li>Slave: 5 nodes</li>
<li>Manage: 1 nodes</li>
<li>Kafka: 3 nodes</li>
</ul>
</div></blockquote>
<p>hosts.large_sample:</p>
<blockquote>
<div><ul class="simple">
<li>NameNode: 2 nodes</li>
<li>Zookeeper and JournalNode: 3 nodes</li>
<li>ResourceManager: 2 nodes</li>
<li>Client: 1 node</li>
<li>Slave: 10 nodes</li>
<li>Manage: 1 nodes</li>
<li>Kafka: 3 nodes</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Both hosts sample includes &#8220;hadoop_pseudo&#8221; group,
which is the pseudo Hadoop environment.</p>
</div>
</div>
<div class="section" id="about-groups-in-inventory">
<h2>About groups in inventory<a class="headerlink" href="#about-groups-in-inventory" title="Permalink to this headline">¶</a></h2>
<p>This example of inventory includes the following configured groups.</p>
<p><strong>Main group</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="75%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">group</th>
<th class="head">description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>production</td>
<td>The top group which represent whole of this environment.
This group is used to define the environmental specific parameters
using group variables.</td>
</tr>
<tr class="row-odd"><td>local</td>
<td>The dummy group to define localhost in inventory</td>
</tr>
<tr class="row-even"><td>hadoop_all</td>
<td>This group includes all groups and nodes in Hadoop cluster</td>
</tr>
<tr class="row-odd"><td>hadoop_master</td>
<td>This group includes all groups and nodes which provides
Hadoop&#8217;s master service, such as NameNodes.</td>
</tr>
<tr class="row-even"><td>hadoop_namenode</td>
<td>This group includes both of primary NameNode and backup NameNode</td>
</tr>
<tr class="row-odd"><td>hadoop_journalnode</td>
<td>This group includes JournalNodes</td>
</tr>
<tr class="row-even"><td>hadoop_zookeeperserver</td>
<td>This group includes Zookeeper nodes.
The parameter &#8220;zookeeper_server_id&#8221; is configured with each nodes.</td>
</tr>
<tr class="row-odd"><td>hadoop_resourcemanager</td>
<td>This group includes ResourceManagers</td>
</tr>
<tr class="row-even"><td>hadoop_other</td>
<td>This group includes node to provides Hadoop side services,
such as HistoryServer.</td>
</tr>
<tr class="row-odd"><td>hadoop_slave</td>
<td>This group includes slave nodes of Hadoop</td>
</tr>
<tr class="row-even"><td>hadoop_client</td>
<td>This group includes all groups and nodes which is used
as clients of Hadoop and other services.</td>
</tr>
<tr class="row-odd"><td>hadoop_pseudo</td>
<td>This group includes a ndoe which provide Hadoop pseudo environment.</td>
</tr>
<tr class="row-even"><td>manage</td>
<td>This group includes nodes to control clusters</td>
</tr>
<tr class="row-odd"><td>kafka_cluster</td>
<td>This group includes Kafka brokers of Apache Kafka (Community version)</td>
</tr>
<tr class="row-even"><td>confluent_kafka_cluster</td>
<td>This group includes Kafka brokers of Confluent Kafka</td>
</tr>
<tr class="row-odd"><td>confluent_schema_registry</td>
<td>This group includes Confluent&#8217;s schema registry service nodes</td>
</tr>
<tr class="row-even"><td>confluent_kafka_rest</td>
<td>This group includes Confluent&#8217;s REST Proxy serivce nodes</td>
</tr>
</tbody>
</table>
<p>If you are managing several Hadoop cluster and environment, such as production, test, etc,
you can use the top-level group to define such environment.
The group variables of each group may define parameters which are specific to each environment.</p>
<p>Example:</p>
<div class="highlight-python"><pre>group_vars/all/something        ... This includes default parameters for all environment
group_vars/production/something ... This includes parameters which are specific to the production environment
group_vars/test/something       ... This includes parameters which are specific to the test environment</pre>
</div>
<p>If you define several inventory file which represent each environment,
you can use them to swich environments which you want to configure in executing ansible-playbook command.</p>
</div>
<div class="section" id="id1">
<h2>About playbooks<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>This project has two types of playbooks.</p>
<ul class="simple">
<li>Playbooks for configuration<ul>
<li>These are used to install middlewares and configure parameters of OS and middlewares.</li>
</ul>
</li>
<li>Playbooks for operation<ul>
<li>These are used to operate OS&#8217;s services and middleware services.</li>
</ul>
</li>
</ul>
<div class="section" id="playbooks-for-configuration">
<h3>Playbooks for configuration<a class="headerlink" href="#playbooks-for-configuration" title="Permalink to this headline">¶</a></h3>
<p>We can use playbooks in playbooks/conf directory to configure servers.</p>
<p><strong>abstract</strong></p>
<table border="1" class="docutils">
<colgroup>
<col width="31%" />
<col width="69%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Directory</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>playbooks/conf/common</td>
<td>Common and basic configuration</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/cdh5</td>
<td>Configuration of CDH5 environment</td>
</tr>
<tr class="row-even"><td>playbooks/conf/cdh5_pseudo</td>
<td>Configuration of CDH5 Pseudo environment</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/ansible</td>
<td>Configuration of Ansible environment</td>
</tr>
<tr class="row-even"><td>playbooks/conf/ganglia</td>
<td>Configuration of Ganglia</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/influxdb</td>
<td>Configuration of InfluxDB and Grafana</td>
</tr>
<tr class="row-even"><td>playbooks/conf/spark_comm</td>
<td>Configuration of Spark community edition</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/zeppelin</td>
<td>Configuration of Zeppelin community edition</td>
</tr>
<tr class="row-even"><td>playbooks/conf/fluentd</td>
<td>Configuration of fluentd and td-agent</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/kafka</td>
<td>Configuration of Kafka</td>
</tr>
<tr class="row-even"><td>playbooks/conf/confluent</td>
<td>Configuration of Confluent packages including Kafka</td>
</tr>
<tr class="row-odd"><td>playbooks/conf/ambari</td>
<td>Configuration of Ambari</td>
</tr>
</tbody>
</table>
<div class="section" id="common">
<h4>common<a class="headerlink" href="#common" title="Permalink to this headline">¶</a></h4>
<p>This is a set of common and basic configurations.</p>
<ul class="simple">
<li>playbooks/conf/common/common_all.yml<ul>
<li>This playbook executes all basic roles</li>
</ul>
</li>
<li>playbooks/conf/common/common_only_common.yml<ul>
<li>This playbook only executes &#8220;common&#8221; role</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="cdh5">
<h4>cdh5<a class="headerlink" href="#cdh5" title="Permalink to this headline">¶</a></h4>
<p>This is a set of configurations to construct CDH5 environment.</p>
<ul class="simple">
<li>cdh5_all.yml<ul>
<li>This playbook is a comprehensive playbook which includes all other playbooks.
You can build whole CDH5 environment.</li>
</ul>
</li>
<li>cdh5_cl.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_cl&#8221; role to build Hadoop Client environment</li>
</ul>
</li>
<li>cdh5_journalnode.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_jn&#8221; role to build HDFS JournalNode environment</li>
</ul>
</li>
<li>cdh5_namenode.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_nn&#8221; role to build HDFS NameNode environment</li>
</ul>
</li>
<li>cdh5_other.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_ot&#8221; role to build MapReduce HistoryServer and YARN Proxy environments</li>
</ul>
</li>
<li>cdh5_resourcemanager.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_rm&#8221; role to build YARN ResourceManager environment</li>
</ul>
</li>
<li>cdh5_slave.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_sl&#8221; role to build HDFS DataNode and YARN NodeManager environments</li>
</ul>
</li>
<li>cdh5_spark.yml<ul>
<li>This playbook executes basic roles and &#8220;cdh5_spark&#8221; role to build Spark Core environment on Client Node</li>
</ul>
</li>
<li>cdh5_zookeeper.yml<ul>
<li>This playbook executes basic roles and &#8220;zookeeper_server&#8221; role to build Zookeeper environment</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="cdh5-pseudo">
<h4>cdh5_pseudo<a class="headerlink" href="#cdh5-pseudo" title="Permalink to this headline">¶</a></h4>
<p>This is a set of configurations to construct CDH5 pseudo environment.</p>
<ul class="simple">
<li>cdh5_pseudo.yml<ul>
<li>You can build whole CDH5 pseudo environment.</li>
</ul>
</li>
<li>cdh5_spark.yml<ul>
<li>You can build spark environment on CDH5 pseudo.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="ansible">
<h4>ansible<a class="headerlink" href="#ansible" title="Permalink to this headline">¶</a></h4>
<p>This is a set of configuration about Ansible environment.
If you have manually configured Ansible environment, such as ansible.cfg, inventory file and so on,
you don&#8217;t need these playbooks.</p>
<ul class="simple">
<li>ansible_client.yml<ul>
<li>This playbook executes &#8220;ansible&#8221; role to configure nodes where we execute ansible command</li>
</ul>
</li>
<li>ansible_remote.yml<ul>
<li>This playbook executes &#8220;ansible_remote&#8221; role to configure nodes which are configured by ansible</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="ganglia">
<h4>ganglia<a class="headerlink" href="#ganglia" title="Permalink to this headline">¶</a></h4>
<p>This is  a set of configuration about Ganglia.
We have two playbooks for Ganglia master and slave.</p>
<ul class="simple">
<li>ganglia_all.yml<ul>
<li>The wrapper playbook of configuration of both of Ganglia master and slave</li>
</ul>
</li>
<li>ganglia_master.yml<ul>
<li>The playbook to configure Ganglia master</li>
</ul>
</li>
<li>ganglia_slave.yml<ul>
<li>The playbook to configure Ganglia slave</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="influxdb">
<h4>influxdb<a class="headerlink" href="#influxdb" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>all.yml<ul>
<li>Configure influxdb and Grafana.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="spark-comm">
<h4>spark_comm<a class="headerlink" href="#spark-comm" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>all.yml<ul>
<li>Configure all nodes</li>
</ul>
</li>
<li>spark_base.yml<ul>
<li>Execute basic configuration of Spark</li>
</ul>
</li>
<li>spark_client.yml<ul>
<li>Configure client environment to develop Spark applications</li>
</ul>
</li>
<li>spark_history.yml<ul>
<li>Configure environment to run Spark history server</li>
</ul>
</li>
<li>spark_libs.yml<ul>
<li>Configure library environment to use native libraries in MLlib</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="zeppelin">
<h4>zeppelin<a class="headerlink" href="#zeppelin" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>zeppelin.yml<ul>
<li>Configure zeppelin environment</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="fluentd">
<h4>fluentd<a class="headerlink" href="#fluentd" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>fluentd.yml<ul>
<li>Configure fluentd</li>
</ul>
</li>
<li>td_agent.yml<ul>
<li>Configure td-agent</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="kafka">
<h4>kafka<a class="headerlink" href="#kafka" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>kafka_brocker.yml<ul>
<li>Configure Kafka broker nodes.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="confluent">
<h4>confluent<a class="headerlink" href="#confluent" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>kafka_broker.yml<ul>
<li>Configure Confluent Kafka brokers</li>
</ul>
</li>
<li>kafka_schema.yml<ul>
<li>Configure Confluent Schema Registry</li>
</ul>
</li>
<li>kafka_rest.yml<ul>
<li>Configure Confluent REST Proxy</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="ambari">
<h4>ambari<a class="headerlink" href="#ambari" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>ambari_agent.yml<ul>
<li>Configure Ambari agent manually (Not through Ambari server)</li>
</ul>
</li>
<li>ambari_server.yml<ul>
<li>Configure Ambari server</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="jenkins">
<h4>jenkins<a class="headerlink" href="#jenkins" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>jenkins.yml<ul>
<li>Configure Jenkins server</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="playbooks-for-operation">
<h3>Playbooks for operation<a class="headerlink" href="#playbooks-for-operation" title="Permalink to this headline">¶</a></h3>
<p>We can use playbooks in playbooks/operation directory to operate services.</p>
<table border="1" class="docutils">
<colgroup>
<col width="32%" />
<col width="68%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Directory</td>
<td>Use for</td>
</tr>
<tr class="row-even"><td>===============================-</td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/cdh5</td>
<td>Operation of Hadoop Services.
e.g. Formating HDFS, Start/Stop services, ...</td>
</tr>
<tr class="row-even"><td>playbooks/operation/cdh5_pseudo</td>
<td>Operation of Hadoop Services.
e.g. Formating HDFS, Start/Stop services, ...</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/common</td>
<td>Operations about SSH key exchange.</td>
</tr>
<tr class="row-even"><td>playbooks/operation/ec2</td>
<td>Operation to boot EC2 instances</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/httpd</td>
<td>Start and stop httpd</td>
</tr>
<tr class="row-even"><td>playbooks/operation/influxdb</td>
<td>Operation about InfluxDB initilization</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/spark_com</td>
<td>Operation of Spark services and building Spark packages</td>
</tr>
<tr class="row-even"><td>playbooks/operation/zeppelin</td>
<td>Start and stop zeppelin services</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/fluentd</td>
<td>Start and stop td-agent services</td>
</tr>
<tr class="row-even"><td>playbooks/operation/kafka</td>
<td>Start and stop Kafka cluster</td>
</tr>
<tr class="row-odd"><td>playbooks/operation/confluent</td>
<td>Start and stop Confluent services including Kafka</td>
</tr>
<tr class="row-even"><td>playbooks/operation/ambari</td>
<td>Setup Ambari server.
Start and stop each services.</td>
</tr>
</tbody>
</table>
<div class="section" id="id2">
<h4>cdh5<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p>This is a set of operation of Hadoop services.
Please check README in the <em>cdh5</em> directory for more information.</p>
</div>
<div class="section" id="ec2">
<h4>ec2<a class="headerlink" href="#ec2" title="Permalink to this headline">¶</a></h4>
<p>This is a set of operation to boot EC2 instances.
Please check README in the <em>ec2</em> directory for more information.</p>
</div>
<div class="section" id="id3">
<h4>influxdb<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>create_db.yml<ul>
<li>Create all databases in InfluxDB.</li>
</ul>
</li>
<li>create_graphite_db.yml<ul>
<li>Create database in InfluxDB, which hold data gathered by Graphite&#8217;s protocol.
This is mainly used by Spark.</li>
</ul>
</li>
<li>create_grafana_db.yml<ul>
<li>Create database in InfluxDB, which hold Grafana&#8217;s dashboard data.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id4">
<h4>spark_comm<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>make_spark_packages.yml<ul>
<li>Compile Spark sources and build packages</li>
</ul>
</li>
<li>start_spark_historyserver.yml<ul>
<li>Start Spark&#8217;s history server</li>
</ul>
</li>
<li>stop_spark_historyserver.yml<ul>
<li>Stop Spark&#8217;s history server</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id5">
<h4>zeppelin<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>build.yml<ul>
<li>Compile and package Zeppelin</li>
<li>This is helper playbook to build Zeppelin.
You can build Zeppelin according to Zeppelin official web site.</li>
</ul>
</li>
<li>restart_zeppelin.yml<ul>
<li>Stop and start Zeppelin serives</li>
</ul>
</li>
<li>start_zeppelin.yml<ul>
<li>Start zeppelin services by executing zeppelin-daemon.sh</li>
</ul>
</li>
<li>stop_zeppelin.yml<ul>
<li>Stop zeppelin services by executing zeppelin-daemon.sh</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id6">
<h4>fluentd<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>restart_td_agent.yml<ul>
<li>Stop and Start td-agent</li>
</ul>
</li>
<li>start_td_agent.yml<ul>
<li>Start td-agent</li>
</ul>
</li>
<li>stop_td_agent.yml<ul>
<li>Stop td-agent</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id7">
<h4>kafka<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>restart_kafka.yml<ul>
<li>Stop and Start kafka</li>
</ul>
</li>
<li>start_kafka.yml<ul>
<li>Start kafka</li>
</ul>
</li>
<li>stop_kafka.yml<ul>
<li>Stop kafka</li>
</ul>
</li>
<li>create_topic.yml<ul>
<li>Create topic on Kafka cluster</li>
</ul>
</li>
<li>delete_topic.yml<ul>
<li>Delete topic on Kafka cluster</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id8">
<h4>confluent<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>restart_kafka_rest.yml<ul>
<li>Stop and Start REST Proxy service</li>
</ul>
</li>
<li>restart_kafka_server.yml<ul>
<li>Stop and Start Kafka broker service</li>
</ul>
</li>
<li>restart_zookeeper_server.yml<ul>
<li>Stop and Start ZooKeeper serivce</li>
<li>If you configured ZooKeeper service on Kafka broker nodes,
you can use this playbook to control such ZooKeeper serivces.</li>
</ul>
</li>
<li>start_kafka_rest.yml<ul>
<li>Start Kafka REST Proxy serivce</li>
</ul>
</li>
<li>start_kafka_server.yml<ul>
<li>Start Kafka broker service</li>
</ul>
</li>
<li>start_schema_registry.yml<ul>
<li>Start Confluent schema registry service</li>
</ul>
</li>
<li>start_zookeeper_server.yml<ul>
<li>Start ZooKeeper serivce</li>
<li>If you configured ZooKeeper service on Kafka broker nodes,
you can use this playbook to control such ZooKeeper serivces.</li>
</ul>
</li>
<li>stop_kafka_rest.yml<ul>
<li>Stop Kafka REST Proxy serivce</li>
</ul>
</li>
<li>stop_kafka_server.yml<ul>
<li>Stop Kafka broker serivce</li>
</ul>
</li>
<li>stop_schema_registry.yml<ul>
<li>Stop Confluent schema registry service</li>
</ul>
</li>
<li>stop_zookeeper_server.yml<ul>
<li>Stop ZooKeeper serivce</li>
<li>If you configured ZooKeeper service on Kafka broker nodes,
you can use this playbook to control such ZooKeeper serivces.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id9">
<h4>ambari<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li>To setup Ambari server<ul>
<li>setup.yml</li>
</ul>
</li>
<li>Starting and stopping each service<ul>
<li>restart_all.yml</li>
<li>restart_ambari_metrics.yml</li>
<li>restart_hdfs.yml</li>
<li>restart_yarn.yml</li>
<li>restart_zookeeper.yml</li>
<li>start_all.yml</li>
<li>start_ambari_metrics.yml</li>
<li>start_hdfs.yml</li>
<li>start_yarn.yml</li>
<li>start_zookeeper.yml</li>
<li>stop_all.yml</li>
<li>stop_ambari_metrics.yml</li>
<li>stop_hdfs.yml</li>
<li>stop_yarn.yml</li>
<li>stop_zookeeper.yml</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="about-roles">
<h2>About roles<a class="headerlink" href="#about-roles" title="Permalink to this headline">¶</a></h2>
<p>We manage OS and middlewares by using several seperated roles.</p>
<div class="section" id="roles-to-configure-basic-environments">
<h3>Roles to configure basic environments<a class="headerlink" href="#roles-to-configure-basic-environments" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>common</td>
<td>Basic configuration about OS, basic services, and so on</td>
</tr>
<tr class="row-odd"><td>prompt</td>
<td>Configuration of console prompt</td>
</tr>
<tr class="row-even"><td>screen</td>
<td>Configuration of screen command</td>
</tr>
<tr class="row-odd"><td>user</td>
<td>Configuration of users</td>
</tr>
<tr class="row-even"><td>epel</td>
<td>Configuration of EPEL Repository</td>
</tr>
<tr class="row-odd"><td>jdk</td>
<td>Configuraiotn of Oracle JDK</td>
</tr>
<tr class="row-even"><td>scala</td>
<td>Configuraiton of Scala on Hadoop client node</td>
</tr>
<tr class="row-odd"><td>sbt</td>
<td>Configuration of Sbt</td>
</tr>
<tr class="row-even"><td>activator_mini</td>
<td>Configuraiton of Activator mini</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-ansible">
<h3>Roles to configure Ansible<a class="headerlink" href="#roles-to-configure-ansible" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="78%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ansible</td>
<td>Configuration of nodes where you executes ansible command</td>
</tr>
<tr class="row-odd"><td>ansible_remote</td>
<td>Configuration of nodes which is configured ansible</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-boot-ec2-instances-for-hadoop-cluster">
<h3>Roles to boot EC2 instances for Hadoop cluster<a class="headerlink" href="#roles-to-boot-ec2-instances-for-hadoop-cluster" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ec2_hadoop</td>
<td>Boot EC2 instances for Hadoop cluster</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-cdh5-hadoop">
<h3>Roles to configure CDH5 Hadoop<a class="headerlink" href="#roles-to-configure-cdh5-hadoop" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_base</td>
<td>Basic configuraiton about Hadoop</td>
</tr>
<tr class="row-odd"><td>cdh5_jn</td>
<td>Configuration of JournalNode</td>
</tr>
<tr class="row-even"><td>cdh5_nn</td>
<td>Configuraiton of NameNode</td>
</tr>
<tr class="row-odd"><td>cdh5_ot</td>
<td>Configuraiton of HistoryServer and YARN Proxy</td>
</tr>
<tr class="row-even"><td>cdh5_rm</td>
<td>Configuraiton of ResourceManager</td>
</tr>
<tr class="row-odd"><td>cdh5_sl</td>
<td>Configuration of DataNode and NodeManager</td>
</tr>
<tr class="row-even"><td>zookeeper_server</td>
<td>Configuration of Zookeeper server</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-cdh5-pseudo-hadoop">
<h3>Roles to configure CDH5 pseudo Hadoop<a class="headerlink" href="#roles-to-configure-cdh5-pseudo-hadoop" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_pseudo</td>
<td>Basic configuraiton about Hadoop pseudo environment</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-spark-core-on-client-node">
<h3>Roles to configure Spark core on client node<a class="headerlink" href="#roles-to-configure-spark-core-on-client-node" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>cdh5_spark</td>
<td>Configuration of Spark core on Hadoop client node</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-ganglia">
<h3>Roles to configure Ganglia<a class="headerlink" href="#roles-to-configure-ganglia" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ganglia_master</td>
<td>Configuration of Ganglia Master and Web frontend</td>
</tr>
<tr class="row-odd"><td>ganglia_slave</td>
<td>Configuration of Ganglia Slave</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-influxdb-and-grafana">
<h3>Roles to configure InfluxDB and Grafana<a class="headerlink" href="#roles-to-configure-influxdb-and-grafana" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>influxdb</td>
<td>Configuration of InfluxDB</td>
</tr>
<tr class="row-odd"><td>grafana</td>
<td>Configuration of Grafana</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-spark-community-edition">
<h3>Roles to configure Spark community edition<a class="headerlink" href="#roles-to-configure-spark-community-edition" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>spark_comm</td>
<td>Configuration of Spark community edition</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-zeppelin">
<h3>Roles to configure Zeppelin<a class="headerlink" href="#roles-to-configure-zeppelin" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>zeppelin</td>
<td>Configuration of Zeppelin community edition</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-fluentd-or-td-agent">
<h3>Roles to configure fluentd or td-agent<a class="headerlink" href="#roles-to-configure-fluentd-or-td-agent" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>fluentd</td>
<td>Configuration of fluentd (community edition)</td>
</tr>
<tr class="row-odd"><td>td_agent</td>
<td>Configuration of td-agent</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-kafka">
<h3>Roles to configure Kafka<a class="headerlink" href="#roles-to-configure-kafka" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>kafka</td>
<td>Configuration of Kafka cluster</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-confluent">
<h3>Roles to configure Confluent<a class="headerlink" href="#roles-to-configure-confluent" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>confluent_kafka</td>
<td>Configuration of Confluent packages</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-ambari">
<h3>Roles to configure Ambari<a class="headerlink" href="#roles-to-configure-ambari" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ambari_server</td>
<td>Configuration of Ambari server</td>
</tr>
<tr class="row-odd"><td>ambari_agent</td>
<td>Configuration of Ambari agent</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="roles-to-configure-ci-environment">
<h3>Roles to configure CI environment<a class="headerlink" href="#roles-to-configure-ci-environment" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="77%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Role name</th>
<th class="head">Use for</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>jenkins</td>
<td>Configuration of Jenkins</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="how-to-use-this-playbooks">
<h2>How to use this playbooks<a class="headerlink" href="#how-to-use-this-playbooks" title="Permalink to this headline">¶</a></h2>
<p>You can use these playbooks to configure the following configuration.
<strong>These playbooks are independent of each other</strong> .</p>
<ul class="simple">
<li>Ansible client environment to use various Ansible functions</li>
<li>Host name configuration</li>
<li>CDH5 HDFS/YARN environment</li>
</ul>
<div class="section" id="assumption-of-this-section">
<h3>Assumption of this section<a class="headerlink" href="#assumption-of-this-section" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>You have servers described in <a class="reference internal" href="#sec-servers"><em>Servers</em></a> section.</li>
</ul>
</div>
<div class="section" id="how-to-configure-ansible-execution-environment">
<span id="sec-configure-ansible-env"></span><h3>How to configure Ansible execution environment<a class="headerlink" href="#how-to-configure-ansible-execution-environment" title="Permalink to this headline">¶</a></h3>
<p>If you have not configured Ansible execution environment,
you can use the following playbooks for it.</p>
<p>In this section, we start from installing Ansible packages.</p>
<div class="section" id="install-packages">
<h4>Install packages<a class="headerlink" href="#install-packages" title="Permalink to this headline">¶</a></h4>
<p>Install EPEL repository</p>
<div class="highlight-shell"><pre>$ sudo yum install -y epel-release</pre>
</div>
<p>Install Ansible</p>
<div class="highlight-shell"><pre>$ sudo yum install -y ansible</pre>
</div>
</div>
<div class="section" id="id10">
<h4>Clone playbooks<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>Move original /etc/ansible</p>
<div class="highlight-shell"><pre>$ cd /etc
$ sudo mv ansible ansible.org</pre>
</div>
<p>Clone this repository</p>
<div class="highlight-shell"><pre>$ git clone https://github.com/dobachi/ansible-hadoop.git ansible</pre>
</div>
</div>
<div class="section" id="modify-configuration">
<h4>Modify configuration<a class="headerlink" href="#modify-configuration" title="Permalink to this headline">¶</a></h4>
<p>Modify hosts file to be copied to /etc/hosts</p>
<div class="highlight-shell"><pre>$ cd ansible
$ sudo vi roles/common/files/hosts.default</pre>
</div>
</div>
<div class="section" id="execute-playbooks-one-by-one">
<h4>Execute playbooks one by one<a class="headerlink" href="#execute-playbooks-one-by-one" title="Permalink to this headline">¶</a></h4>
<p>Execute ansible-playbook command with common_all.yml</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/common/common_all.yml -k -s -i hosts.sample -e "common_hosts_replace=True"</pre>
</div>
<p>Copy ansible&#8217;s hosts and modify it</p>
<div class="highlight-shell"><pre>$ sudo vi roles/ansible/templates/hosts.default.j2</pre>
</div>
<p>Execute ansible-playbook command with ansible_client.yml</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e "ansible_environment=default ansible_modify_cfg=True"</pre>
</div>
<p>If you use EC2 and need a private key for SSH,
you should specify &#8220;ansible_private_key_file&#8221; paramter.
You should execute command with the parameter instead of the above command</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/ansible/ansible_client.yml -k -s -i hosts.sample -e "ansible_environment=default ansible_modify_cfg=True ansible_private_key_file=${HOME}/mykey.pem"</pre>
</div>
<p>Check whether all nodes are reachable and &#8220;sudo&#8221; is available</p>
<div class="highlight-shell"><pre>$ ansible -m ping hadoop_all -k -s</pre>
</div>
</div>
</div>
<div class="section" id="how-to-boot-ec2-instances-for-hadoop-cluster">
<h3>How to boot EC2 instances for Hadoop cluster<a class="headerlink" href="#how-to-boot-ec2-instances-for-hadoop-cluster" title="Permalink to this headline">¶</a></h3>
<p>If you want to use Hadoop on EC2 instances,
you can use playbooks/operation/ec2/hadoop_nodes_up.yml to boot instances.</p>
<div class="section" id="create-inventory-file">
<h4>Create inventory file<a class="headerlink" href="#create-inventory-file" title="Permalink to this headline">¶</a></h4>
<p>If you don&#8217;t have an inventory file,
create inventory file, /etc/ansible/hosts while referring /etc/ansible/hosts.sample.</p>
</div>
<div class="section" id="define-environment-variables-for-aws-access">
<h4>Define environment variables for AWS access<a class="headerlink" href="#define-environment-variables-for-aws-access" title="Permalink to this headline">¶</a></h4>
<p>We use environment variables to configure AWS access keys.
Define AWS_ACCESS_KEY and AWS_SECRET_KEY in your ~/.bashrc</p>
<div class="highlight-python"><pre>export AWS_ACCESS_KEY=XXXXXXXXXXXXXXXXXXXXXXXXx
export AWS_SECRET_KEY=XXXXXXXXXXXXXXXXXXXXXXXXX</pre>
</div>
<p>If you don&#8217;t have AWS keys,
create keys while referring AWS web site.</p>
</div>
<div class="section" id="define-parameters-for-ec2-hadoop-role">
<h4>Define parameters for ec2_hadoop role<a class="headerlink" href="#define-parameters-for-ec2-hadoop-role" title="Permalink to this headline">¶</a></h4>
<p>You can find the parameter description for ec2_hadoop role in roles/ec2_hadoop/defaults/main.yml</p>
<p>To define your own parameters,
you need to create the group variable file (e.g. group_vars/all/ec2) and write parameter defines in this file.</p>
<p>The following is an example of group_vas/top.</p>
<div class="highlight-python"><pre>ec2_hadoop_group_id: sg-xxxxxxxx

ec2_hadoop_accesskey: xxxxx

ec2_hadoop_itype: xx.xxxxx

ec2_hadoop_master_image: ami-xxxxxxxx
ec2_hadoop_slave_image: ami-xxxxxxxx
ec2_hadoop_client_image: ami-xxxxxxxx

ec2_hadoop_region: xx-xxxxxxxxx-x

ec2_hadoop_vpc_subnet_id: subnet-xxxxxxxx</pre>
</div>
<p>If you don&#8217;t define required parameters,
you will see some errors, like:</p>
<div class="highlight-python"><pre>One or more undefined variables: 'ec2_hadoop_group_id' is undefined</pre>
</div>
</div>
<div class="section" id="apply-playbook">
<h4>Apply playbook<a class="headerlink" href="#apply-playbook" title="Permalink to this headline">¶</a></h4>
<p>Execute ansible-playbook command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -c local</pre>
</div>
<p>As a result, you can find an IP address list, an ansible inventory file and an example of /etc/hosts used in EC2 instances
in /tmp/ec2_&lt;unix epoc time&gt;.
&lt;unix epoc time&gt; is the time you executed this playbook.</p>
</div>
<div class="section" id="supplement-when-you-restart-ec2-instances">
<h4>(supplement) When you restart ec2 instances<a class="headerlink" href="#supplement-when-you-restart-ec2-instances" title="Permalink to this headline">¶</a></h4>
<p>When you restart ec2 instances, public IP addresses may change.
You can obtain new IP address tables by executing the playbook.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/ec2/hadoop_nodes_up.yml -c local</pre>
</div>
</div>
</div>
<div class="section" id="how-to-configure-host-names-of-nodes">
<h3>How to configure host names of nodes<a class="headerlink" href="#how-to-configure-host-names-of-nodes" title="Permalink to this headline">¶</a></h3>
<p>If you want to configure hostname of nodes,
You can use &#8220;common&#8221; role and related playbooks.</p>
<p>Execute ansible-playbook command with common_only_common.yml</p>
<div class="highlight-shell"><pre>$ cd /etc/ansible
$ ansible-playbook playbooks/conf/common/common_only_common.yml -k -s -e "common_config_hostname=True server=hadoop_all"</pre>
</div>
<p>This is usefull for configuration of EC2 instance, because your node may have variety of hostname after each node booted.</p>
</div>
<div class="section" id="how-to-configure-cdh5-hdfs-yarn-environment">
<h3>How to configure CDH5 HDFS/YARN environment<a class="headerlink" href="#how-to-configure-cdh5-hdfs-yarn-environment" title="Permalink to this headline">¶</a></h3>
<p>You can construct CDH5 HDFS/YARN environment by ansible-playbook command.</p>
<div class="section" id="preparement">
<h4>Preparement<a class="headerlink" href="#preparement" title="Permalink to this headline">¶</a></h4>
<p>If you have not configured Ansible execution environment,
you should configure it.
You can reference <a class="reference internal" href="how_to_use_playbooks.html#sec-configure-ansible-env"><em>How to configure Ansible execution environment</em></a> section.</p>
</div>
<div class="section" id="procedure">
<h4>Procedure<a class="headerlink" href="#procedure" title="Permalink to this headline">¶</a></h4>
<p>In the following example, we configure common_hosts_replace is True.
As a result of this parameter configuration, Ansible replace /etc/hosts
by Ansible driver server&#8217;s /etc/ansible/roles/common/files/hosts.default</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5/cdh5_all.yml -k -s -e "common_hosts_replace=True"
$ ansible-playbook playbooks/operation/cdh5/init_zkfc.yml -k -s
$ ansible-playbook playbooks/operation/cdh5/init_hdfs.yml -k -s</pre>
</div>
<p>Start services</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5/start_cluster.yml -k -s</pre>
</div>
</div>
<div class="section" id="how-to-install-spark-environment-on-cdh5-environment">
<h4>How to install Spark environment on CDH5 environment<a class="headerlink" href="#how-to-install-spark-environment-on-cdh5-environment" title="Permalink to this headline">¶</a></h4>
<p>You can install Spark Core into Client node by the following command</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5/cdh5_spark.yml -k -s</pre>
</div>
<p>If you want to start Spark&#8217;s history server,
please execute the following command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5/start_sparkhistory.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="how-to-configure-cdh5-pseudo-environment">
<h3>How to configure CDH5 Pseudo environment<a class="headerlink" href="#how-to-configure-cdh5-pseudo-environment" title="Permalink to this headline">¶</a></h3>
<p>You can construct CDH5 HDFS/YARN environment by ansible-playbook command.</p>
<div class="section" id="id11">
<h4>Preparement<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<p>If you have not configured Ansible execution environment,
you should configure it.
You can reference <a class="reference internal" href="how_to_use_playbooks.html#sec-configure-ansible-env"><em>How to configure Ansible execution environment</em></a> section.</p>
</div>
<div class="section" id="id12">
<h4>Procedure<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<p>In the following example, we configure common_hosts_replace is True.
As a result of this parameter configuration, Ansible replace /etc/hosts
by Ansible driver server&#8217;s /etc/ansible/roles/common/files/hosts.default</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_pseudo.yml -k -s -e "common_hosts_replace=True"
$ ansible-playbook playbooks/operation/cdh5_pseudo/init_hdfs.yml -k -s</pre>
</div>
<p>Start services</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5_pseudo/start_cluster.yml -k -s</pre>
</div>
</div>
<div class="section" id="how-to-install-spark-environment-on-hadoop-pseudo-environment">
<h4>How to install Spark environment on Hadoop pseudo environment<a class="headerlink" href="#how-to-install-spark-environment-on-hadoop-pseudo-environment" title="Permalink to this headline">¶</a></h4>
<p>You can install Spark Core into Client node by the following command</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/cdh5_pseudo/cdh5_spark.yml -k -s</pre>
</div>
<p>If you want to start Spark&#8217;s history server,
please execute the following command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/cdh5_pseudo/start_sparkhistory.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="how-to-install-ganglia-environment">
<h3>How to install Ganglia environment<a class="headerlink" href="#how-to-install-ganglia-environment" title="Permalink to this headline">¶</a></h3>
<p>You can install Gaglia services with the following command:</p>
<div class="highlight-python"><pre>.. code-block:: shell</pre>
</div>
<blockquote>
<div>$ ansible-playbook playbooks/conf/ganglia/ganglia_all.yml -k -s</div></blockquote>
<div class="section" id="how-to-use-unicast-for-communication-between-gmonds">
<h4>How to use unicast for communication between gmonds<a class="headerlink" href="#how-to-use-unicast-for-communication-between-gmonds" title="Permalink to this headline">¶</a></h4>
<p>This playbook uses multicast for communication between gmonds as default.
In some situcation, you may want to use unicast.
For example, you are using ec2 of AWS.</p>
<p>The parameter &#8220;ganglia_slave_use_unicast&#8221; is used to define
whether you use unicast or not.
If you set this parameter True in your group_vars, you can use unicast.</p>
<p>Example(group_vars/all/ganglia):</p>
<div class="highlight-python"><pre>ganglia_slave_use_unicast: True</pre>
</div>
<p>Please configure the parameter &#8220;ganglia_slave_host&#8221; as well as &#8220;ganglia_slave_use_unicast&#8221;
This parameter is used to define the destination which each gmond sends metrics,
and should be a representative node which gmetad connect.</p>
</div>
</div>
<div class="section" id="how-to-install-and-configure-influxdb-and-grafana">
<h3>How to install and configure InfluxDB and Grafana<a class="headerlink" href="#how-to-install-and-configure-influxdb-and-grafana" title="Permalink to this headline">¶</a></h3>
<p>You can install InfluxDB and Grafana services with the followign command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/influxdb/all.yml -k -s</pre>
</div>
<p>Then, create a database in InfulxDB to hold data gathered by Graphite&#8217;s protocol.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/influxdb/create_graphite_db.yml -k -s</pre>
</div>
<p>Create a database in InfulxDB to store Grafana&#8217;s dashboard data.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/influxdb/create_grafana_db.yml -k -s</pre>
</div>
<p>The database&#8217;s name and user name to connect the database is
configured in group_vars/all/meta, group_vars/all/influxdb and group_vars/all/grafana like the following.</p>
<p><strong>group_vars/all/meta</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">meta_graphitedb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;graphite&#39;</span>
<span class="l-Scalar-Plain">meta_grafanadb_in_influxdb</span><span class="p-Indicator">:</span> <span class="s">&#39;grafana&#39;</span>
</pre></div>
</div>
<p><strong>group_vars/all/influxdb</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">influxdb_server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_admin_user</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
<span class="l-Scalar-Plain">influxdb_graphite_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
<span class="l-Scalar-Plain">influxdb_grafana_db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
</pre></div>
</div>
<p><strong>group_vars/all/grafana</strong></p>
<div class="highlight-yaml"><div class="highlight"><pre><span class="l-Scalar-Plain">grafana_influxdb_list</span><span class="p-Indicator">:</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_graphitedb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;false&quot;</span>
  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">server</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">groups[&#39;hadoop_other&#39;][0]</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">db_name</span><span class="p-Indicator">:</span> <span class="s">&quot;{{</span><span class="nv"> </span><span class="s">meta_grafanadb_in_influxdb</span><span class="nv"> </span><span class="s">}}&quot;</span>
    <span class="l-Scalar-Plain">admin_name</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">admin_pass</span><span class="p-Indicator">:</span> <span class="s">&quot;root&quot;</span>
    <span class="l-Scalar-Plain">grafanaDB</span><span class="p-Indicator">:</span> <span class="s">&quot;true&quot;</span>
</pre></div>
</div>
<p>Please read <a class="reference external" href="http://grafana.org/docs/features/intro/">Grafana&#8217;s documents</a> to learn
how to configure graphs.</p>
</div>
<div class="section" id="how-to-install-spark-community-edition">
<h3>How to install Spark community edition<a class="headerlink" href="#how-to-install-spark-community-edition" title="Permalink to this headline">¶</a></h3>
<div class="section" id="obtain-package-or-compile-sources">
<h4>Obtain package or compile sources<a class="headerlink" href="#obtain-package-or-compile-sources" title="Permalink to this headline">¶</a></h4>
<p>You can get Spark pacakge from <a class="reference external" href="https://spark.apache.org/downloads.html">Spark official download site</a> .</p>
<p>If you want to use a package compiled by your self,
you should build it according to <a class="reference external" href="https://spark.apache.org/docs/latest/building-spark.html">Spark offical build procedure</a> .</p>
<p>You can also use playbooks/operation/spark_comm/make_spark_packages.yml to build it.
When you use this playbook, please specify the following parameters used in this playbook.</p>
<ul class="simple">
<li>spark_comm_src_dir</li>
<li>spark_comm_version</li>
<li>spark_comm_mvn_options</li>
<li>spark_comm_hadoop_version</li>
</ul>
</div>
<div class="section" id="confiure-parameters">
<h4>Confiure parameters<a class="headerlink" href="#confiure-parameters" title="Permalink to this headline">¶</a></h4>
<p>You can use playbooks/conf/spark_comm/all.yml to configure Spark community edition envirionment.</p>
<p>This playbooks and roles expect to get Spark tar package by HTTP method.
You should configure the following parameter to specify where Ansible should get Spark tar package.</p>
<ul class="simple">
<li>spark_comm_package_url_base</li>
<li>spark_comm_package_name</li>
</ul>
<p>The download URL is consited like {{ spark_comm_package_url_base }}/{{ spark_comm_package_name }}.tgz
For example, if the download URL is &#8220;<a class="reference external" href="http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz">http://example.local/spark/spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2.tgz</a>&#8221;,
spark_comm_package_url_base is &#8220;<a class="reference external" href="http://example.local/spark">http://example.local/spark</a>&#8221; and spark_comm_package_name is &#8220;spark-1.4.0-SNAPSHOT-bin-2.5.0-cdh5.3.2&#8221;.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">spark_comm_package_name does not include &#8221;.tgz&#8221;</p>
</div>
</div>
<div class="section" id="execute-playbooks">
<h4>Execute playbooks<a class="headerlink" href="#execute-playbooks" title="Permalink to this headline">¶</a></h4>
<p>After configuration of parameters, you can execute Ansible playbooks.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/spark_comm/all.yml -k -s</pre>
</div>
</div>
<div class="section" id="stat-history-server">
<h4>Stat history server<a class="headerlink" href="#stat-history-server" title="Permalink to this headline">¶</a></h4>
<p>Start Spark&#8217;s history server by the following command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/spark_comm/start_spark_historyserver.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="configure-zeppelin">
<h3>Configure Zeppelin<a class="headerlink" href="#configure-zeppelin" title="Permalink to this headline">¶</a></h3>
<div class="section" id="obtain-sources-and-build">
<h4>Obtain sources and build<a class="headerlink" href="#obtain-sources-and-build" title="Permalink to this headline">¶</a></h4>
<p>First, according to <a class="reference external" href="https://github.com/apache/incubator-zeppelin/blob/master/README.md">Official README</a> , you need to compile source codes and make a package.</p>
<p>Please take care about the compile option.
You should specify Spark and Hadoop versions you use now.</p>
<p>The following is an example to configure CDH5.3.3、Spark1.3、YARN environment.</p>
<div class="highlight-shell"><pre>$ mvn clean package -Pspark-1.3 -Dhadoop.version=2.5.0-cdh5.3.3 -Phadoop-2.4 -Pyarn -DskipTests</pre>
</div>
<p>You can also use playbooks/operation/zeppelin/build.yml, the helper playbook.
Before executing this playbook, please configure the following parameters in the playbook.</p>
<ul class="simple">
<li>zeppelin_git_url</li>
<li>zeppelin_src_dir</li>
<li>zeppelin_version</li>
<li>zeppelin_comiple_flag</li>
<li>zeppelin_hadoop_version</li>
</ul>
<p>Finally, the playbook to configure Zeppelin make use of the package
which you compiled the above procedure.
The package is downloaded from web service by HTTP,
so that you need to put the package on a HTTP web server.</p>
</div>
<div class="section" id="executing-playbook">
<h4>Executing playbook<a class="headerlink" href="#executing-playbook" title="Permalink to this headline">¶</a></h4>
<p>To configure Zeppelin, please execute the following playbook.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/zeppelin/zeppelin.yml -k -s</pre>
</div>
<p>After finishing configuration, you need to start Zeppelin service.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/zeppelin/start_zeppelin.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="configure-kafka-cluster">
<h3>Configure Kafka cluster<a class="headerlink" href="#configure-kafka-cluster" title="Permalink to this headline">¶</a></h3>
<div class="section" id="information">
<h4>Information<a class="headerlink" href="#information" title="Permalink to this headline">¶</a></h4>
<p>We assume that Zookeeper ensemble was congured on master01, master02 and master03.
If you have any other Zookeeper ensemble, you should modify kafka role&#8217;s parameters.</p>
</div>
<div class="section" id="id13">
<h4>Executing playbook<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h4>
<p>To configure Kafka cluster, please execute the following playbook.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/kafka/kafka_broker.yml -k -s</pre>
</div>
<p>After finishing configuration, you need to start Kafka cluster.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/kafka/start_kafka.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="configure-confluent-services">
<h3>Configure Confluent services<a class="headerlink" href="#configure-confluent-services" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id14">
<h4>Information<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<p>We assume that Zookeeper ensemble was congured on master01, master02 and master03.
If you have any other Zookeeper ensemble, you should modify kafka role&#8217;s parameters.</p>
</div>
<div class="section" id="id15">
<h4>Executing playbook<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<p>To configure Kafka broker cluster, please execute the following playbook.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/confluent/kafka_broker.yml -k -s</pre>
</div>
<p>After finishing configuration, you need to start Kafka cluster.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/start_kafka_server.yml -k -s</pre>
</div>
<p>As the same as the above procedure,
you can install Schema Registry and Kafka REST Proxy
by using kafka_schema.yml and kafka_rest.yml in playbooks/conf/confluent directory.
And, use the following playbooks to these services,</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/start_schema_registry.yml -k -s
$ ansible-playbook playbooks/operation/start_kafka_rest.yml -k -s</pre>
</div>
</div>
</div>
<div class="section" id="configure-ambari">
<h3>Configure Ambari<a class="headerlink" href="#configure-ambari" title="Permalink to this headline">¶</a></h3>
<p>To install the basic packages, execute the following command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/ambari/ambari_server.yml -k -s</pre>
</div>
<p>Install Ambari agent to all machines.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/ambari/ambari_agent.yml -k -s</pre>
</div>
<p>Execute initilization of Ambari server.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/operation/ambari/setup.yml -k -s</pre>
</div>
<p>Then you can access Ambari web UI on &#8220;manage&#8221; node.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Todo: blueprint</p>
</div>
</div>
<div class="section" id="configure-jenkins">
<h3>Configure Jenkins<a class="headerlink" href="#configure-jenkins" title="Permalink to this headline">¶</a></h3>
<p>To  install Jenkins and related packages, execute the following command.</p>
<div class="highlight-shell"><pre>$ ansible-playbook playbooks/conf/jenkins/jenkins.yml -k -s</pre>
</div>
<p>Soon, Jenkins service is started.
Please read official documents for the detailed information.</p>
<p><a class="reference external" href="https://jenkins.io/doc/">https://jenkins.io/doc/</a></p>
</div>
</div>
</div>


      </div>
      <div class="bottomnav">
      
        <p>
        <a class="uplink" href="index.html">Contents</a>
        </p>

      </div>

    <div class="footer">
        &copy; Copyright 2014, dobachi.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>